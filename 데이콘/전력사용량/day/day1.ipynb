{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('edit_train.csv')\n",
    "test=pd.read_csv('edit_test.csv')\n",
    "submission=pd.read_csv('energy/sample_submission.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['date_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns, axis=1)\n",
    "test = test.drop(columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train.drop('전력사용량(kWh)', axis=1)\n",
    "label = train[['전력사용량(kWh)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ================== Fold 1 ==================\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttraining's l2: 121638\tvalid_1's l2: 127684\n",
      "[100]\ttraining's l2: 83322.7\tvalid_1's l2: 91489.6\n",
      "[150]\ttraining's l2: 70728.9\tvalid_1's l2: 79880\n",
      "[200]\ttraining's l2: 62325\tvalid_1's l2: 72632.7\n",
      "[250]\ttraining's l2: 56006.7\tvalid_1's l2: 67484.1\n",
      "[300]\ttraining's l2: 52113.7\tvalid_1's l2: 64290.8\n",
      "[350]\ttraining's l2: 49261.9\tvalid_1's l2: 62273.9\n",
      "[400]\ttraining's l2: 46930.9\tvalid_1's l2: 60739\n",
      "[450]\ttraining's l2: 44412.7\tvalid_1's l2: 58939.2\n",
      "[500]\ttraining's l2: 42087.9\tvalid_1's l2: 57210.5\n",
      "[550]\ttraining's l2: 40416.5\tvalid_1's l2: 55991\n",
      "[600]\ttraining's l2: 39032.9\tvalid_1's l2: 54974.1\n",
      "[650]\ttraining's l2: 37518\tvalid_1's l2: 54028.5\n",
      "[700]\ttraining's l2: 36414.5\tvalid_1's l2: 53398.5\n",
      "[750]\ttraining's l2: 35055.2\tvalid_1's l2: 52454.3\n",
      "[800]\ttraining's l2: 33897.9\tvalid_1's l2: 51653.3\n",
      "[850]\ttraining's l2: 33008.5\tvalid_1's l2: 51405\n",
      "[900]\ttraining's l2: 31886.3\tvalid_1's l2: 50978.1\n",
      "[950]\ttraining's l2: 31065.2\tvalid_1's l2: 50551.7\n",
      "[1000]\ttraining's l2: 30273.2\tvalid_1's l2: 50279.4\n",
      "[1050]\ttraining's l2: 29572.7\tvalid_1's l2: 50049.2\n",
      "[1100]\ttraining's l2: 28855.3\tvalid_1's l2: 49723.9\n",
      "[1150]\ttraining's l2: 28165.2\tvalid_1's l2: 49390.5\n",
      "[1200]\ttraining's l2: 27534.3\tvalid_1's l2: 49101.4\n",
      "[1250]\ttraining's l2: 26931.3\tvalid_1's l2: 48850.1\n",
      "[1300]\ttraining's l2: 26369.3\tvalid_1's l2: 48592.1\n",
      "[1350]\ttraining's l2: 25778.2\tvalid_1's l2: 48227\n",
      "[1400]\ttraining's l2: 25164.3\tvalid_1's l2: 47958.7\n",
      "[1450]\ttraining's l2: 24621.3\tvalid_1's l2: 47754.1\n",
      "[1500]\ttraining's l2: 24096.5\tvalid_1's l2: 47653.9\n",
      "[1550]\ttraining's l2: 23650.8\tvalid_1's l2: 47464.6\n",
      "[1600]\ttraining's l2: 23197.3\tvalid_1's l2: 47279.5\n",
      "Early stopping, best iteration is:\n",
      "[1599]\ttraining's l2: 23204.5\tvalid_1's l2: 47272.9\n",
      "\n",
      " ================== Fold 2 ==================\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttraining's l2: 126242\tvalid_1's l2: 123747\n",
      "[100]\ttraining's l2: 86911.2\tvalid_1's l2: 85747.8\n",
      "[150]\ttraining's l2: 73937.7\tvalid_1's l2: 74105.1\n",
      "[200]\ttraining's l2: 64913\tvalid_1's l2: 66514.7\n",
      "[250]\ttraining's l2: 58698.1\tvalid_1's l2: 61284.8\n",
      "[300]\ttraining's l2: 54341.2\tvalid_1's l2: 57690.6\n",
      "[350]\ttraining's l2: 51648.1\tvalid_1's l2: 55826.7\n",
      "[400]\ttraining's l2: 48963.7\tvalid_1's l2: 54201.6\n",
      "[450]\ttraining's l2: 46378.9\tvalid_1's l2: 52757.2\n",
      "[500]\ttraining's l2: 44187.4\tvalid_1's l2: 51500.5\n",
      "[550]\ttraining's l2: 42288.9\tvalid_1's l2: 50386.1\n",
      "[600]\ttraining's l2: 40611.6\tvalid_1's l2: 49323.1\n",
      "[650]\ttraining's l2: 39062.9\tvalid_1's l2: 48440.8\n",
      "[700]\ttraining's l2: 37760.5\tvalid_1's l2: 47805.7\n",
      "[750]\ttraining's l2: 36505.9\tvalid_1's l2: 47199.7\n",
      "[800]\ttraining's l2: 35319.6\tvalid_1's l2: 46513.1\n",
      "[850]\ttraining's l2: 34216.6\tvalid_1's l2: 45933.5\n",
      "[900]\ttraining's l2: 33401.2\tvalid_1's l2: 45471\n",
      "[950]\ttraining's l2: 32389.4\tvalid_1's l2: 45014.4\n",
      "[1000]\ttraining's l2: 31601.4\tvalid_1's l2: 44632.8\n",
      "[1050]\ttraining's l2: 30902.3\tvalid_1's l2: 44323\n",
      "[1100]\ttraining's l2: 30236.5\tvalid_1's l2: 43975.8\n",
      "[1150]\ttraining's l2: 29654.2\tvalid_1's l2: 43752.8\n",
      "[1200]\ttraining's l2: 28760\tvalid_1's l2: 43207.6\n",
      "[1250]\ttraining's l2: 28063.9\tvalid_1's l2: 42860.9\n",
      "[1300]\ttraining's l2: 27422\tvalid_1's l2: 42529.8\n",
      "[1350]\ttraining's l2: 26796.6\tvalid_1's l2: 42346.5\n",
      "[1400]\ttraining's l2: 26224.6\tvalid_1's l2: 42132.7\n",
      "[1450]\ttraining's l2: 25745.9\tvalid_1's l2: 41913.6\n",
      "[1500]\ttraining's l2: 25318.7\tvalid_1's l2: 41749.2\n",
      "[1550]\ttraining's l2: 24826.6\tvalid_1's l2: 41627.2\n",
      "[1600]\ttraining's l2: 24404.3\tvalid_1's l2: 41445.2\n",
      "[1650]\ttraining's l2: 23920.9\tvalid_1's l2: 41272.5\n",
      "[1700]\ttraining's l2: 23510.4\tvalid_1's l2: 41182\n",
      "[1750]\ttraining's l2: 23129.1\tvalid_1's l2: 41107.9\n",
      "[1800]\ttraining's l2: 22715.3\tvalid_1's l2: 40975\n",
      "[1850]\ttraining's l2: 22324.6\tvalid_1's l2: 40845.8\n",
      "[1900]\ttraining's l2: 21951\tvalid_1's l2: 40691.2\n",
      "[1950]\ttraining's l2: 21551.1\tvalid_1's l2: 40546\n",
      "[2000]\ttraining's l2: 21173.5\tvalid_1's l2: 40400.9\n",
      "[2050]\ttraining's l2: 20758.1\tvalid_1's l2: 40214\n",
      "[2100]\ttraining's l2: 20454\tvalid_1's l2: 40085.5\n",
      "[2150]\ttraining's l2: 20091.9\tvalid_1's l2: 40006.1\n",
      "[2200]\ttraining's l2: 19753.5\tvalid_1's l2: 39893.7\n",
      "[2250]\ttraining's l2: 19464.6\tvalid_1's l2: 39801.3\n",
      "[2300]\ttraining's l2: 19208.9\tvalid_1's l2: 39735.1\n",
      "[2350]\ttraining's l2: 18882.1\tvalid_1's l2: 39664\n",
      "[2400]\ttraining's l2: 18625.6\tvalid_1's l2: 39575.4\n",
      "[2450]\ttraining's l2: 18355.4\tvalid_1's l2: 39508.3\n",
      "[2500]\ttraining's l2: 18096.4\tvalid_1's l2: 39432.2\n",
      "[2550]\ttraining's l2: 17859.3\tvalid_1's l2: 39417.7\n",
      "[2600]\ttraining's l2: 17598.1\tvalid_1's l2: 39357.6\n",
      "[2650]\ttraining's l2: 17397.1\tvalid_1's l2: 39324.8\n",
      "[2700]\ttraining's l2: 17198.9\tvalid_1's l2: 39285.3\n",
      "[2750]\ttraining's l2: 17000\tvalid_1's l2: 39232.8\n",
      "[2800]\ttraining's l2: 16800.5\tvalid_1's l2: 39197.1\n",
      "Early stopping, best iteration is:\n",
      "[2817]\ttraining's l2: 16723.5\tvalid_1's l2: 39172.8\n",
      "\n",
      " ================== Fold 3 ==================\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttraining's l2: 125254\tvalid_1's l2: 123394\n",
      "[100]\ttraining's l2: 85631.9\tvalid_1's l2: 87159\n",
      "[150]\ttraining's l2: 73033.5\tvalid_1's l2: 76030.1\n",
      "[200]\ttraining's l2: 64310.8\tvalid_1's l2: 68626.4\n",
      "[250]\ttraining's l2: 59594.1\tvalid_1's l2: 64778.4\n",
      "[300]\ttraining's l2: 54863.2\tvalid_1's l2: 60720.1\n",
      "[350]\ttraining's l2: 51222.6\tvalid_1's l2: 58530.5\n",
      "[400]\ttraining's l2: 48395\tvalid_1's l2: 56635.7\n",
      "[450]\ttraining's l2: 45837.7\tvalid_1's l2: 54999.9\n",
      "[500]\ttraining's l2: 43381.7\tvalid_1's l2: 53262\n",
      "[550]\ttraining's l2: 41605.4\tvalid_1's l2: 52274.3\n",
      "[600]\ttraining's l2: 39955.4\tvalid_1's l2: 51177.7\n",
      "[650]\ttraining's l2: 38625.8\tvalid_1's l2: 50331.5\n",
      "[700]\ttraining's l2: 37086\tvalid_1's l2: 49337.6\n",
      "[750]\ttraining's l2: 35577\tvalid_1's l2: 48464.8\n",
      "[800]\ttraining's l2: 34360.6\tvalid_1's l2: 47778.3\n",
      "[850]\ttraining's l2: 33384.9\tvalid_1's l2: 47168.5\n",
      "[900]\ttraining's l2: 32514.6\tvalid_1's l2: 46713.2\n",
      "[950]\ttraining's l2: 31736\tvalid_1's l2: 46342.3\n",
      "[1000]\ttraining's l2: 31008.5\tvalid_1's l2: 45986.9\n",
      "[1050]\ttraining's l2: 30225.3\tvalid_1's l2: 45564.7\n",
      "[1100]\ttraining's l2: 29420.8\tvalid_1's l2: 45112.7\n",
      "[1150]\ttraining's l2: 28688.4\tvalid_1's l2: 44817.7\n",
      "[1200]\ttraining's l2: 28088.7\tvalid_1's l2: 44585.4\n",
      "[1250]\ttraining's l2: 27532\tvalid_1's l2: 44271.1\n",
      "[1300]\ttraining's l2: 27070.2\tvalid_1's l2: 44003.5\n",
      "[1350]\ttraining's l2: 26601.5\tvalid_1's l2: 43797.1\n",
      "[1400]\ttraining's l2: 26107.3\tvalid_1's l2: 43603.8\n",
      "[1450]\ttraining's l2: 25527.6\tvalid_1's l2: 43424\n",
      "[1500]\ttraining's l2: 25085.3\tvalid_1's l2: 43114.4\n",
      "[1550]\ttraining's l2: 24608.1\tvalid_1's l2: 42859.4\n",
      "[1600]\ttraining's l2: 24175\tvalid_1's l2: 42650.1\n",
      "[1650]\ttraining's l2: 23708.5\tvalid_1's l2: 42429.9\n",
      "[1700]\ttraining's l2: 23281.3\tvalid_1's l2: 42209.5\n",
      "[1750]\ttraining's l2: 22927\tvalid_1's l2: 42069.4\n",
      "[1800]\ttraining's l2: 22505\tvalid_1's l2: 41903.4\n",
      "[1850]\ttraining's l2: 22185\tvalid_1's l2: 41748.6\n",
      "[1900]\ttraining's l2: 21749.8\tvalid_1's l2: 41552.9\n",
      "[1950]\ttraining's l2: 21421.6\tvalid_1's l2: 41492.3\n",
      "[2000]\ttraining's l2: 21116.3\tvalid_1's l2: 41403.4\n",
      "[2050]\ttraining's l2: 20774.9\tvalid_1's l2: 41270\n",
      "[2100]\ttraining's l2: 20474.5\tvalid_1's l2: 41124.6\n",
      "[2150]\ttraining's l2: 20108.9\tvalid_1's l2: 40963.8\n",
      "[2200]\ttraining's l2: 19752.4\tvalid_1's l2: 40872.9\n",
      "[2250]\ttraining's l2: 19411.3\tvalid_1's l2: 40699.7\n",
      "[2300]\ttraining's l2: 19117.1\tvalid_1's l2: 40508.5\n",
      "[2350]\ttraining's l2: 18859.6\tvalid_1's l2: 40435.6\n",
      "[2400]\ttraining's l2: 18569.1\tvalid_1's l2: 40318.2\n",
      "[2450]\ttraining's l2: 18245.9\tvalid_1's l2: 40217.6\n",
      "Early stopping, best iteration is:\n",
      "[2447]\ttraining's l2: 18270\tvalid_1's l2: 40200.4\n",
      "\n",
      " ================== Fold 4 ==================\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttraining's l2: 124571\tvalid_1's l2: 129293\n",
      "[100]\ttraining's l2: 86547.3\tvalid_1's l2: 92042\n",
      "[150]\ttraining's l2: 73492.2\tvalid_1's l2: 80443.2\n",
      "[200]\ttraining's l2: 64384.4\tvalid_1's l2: 72293.5\n",
      "[250]\ttraining's l2: 58565.8\tvalid_1's l2: 67196\n",
      "[300]\ttraining's l2: 54337.9\tvalid_1's l2: 64427.1\n",
      "[350]\ttraining's l2: 50547\tvalid_1's l2: 61325.6\n",
      "[400]\ttraining's l2: 47344.7\tvalid_1's l2: 59010.9\n",
      "[450]\ttraining's l2: 44613.7\tvalid_1's l2: 57021\n",
      "[500]\ttraining's l2: 42575\tvalid_1's l2: 55420.7\n",
      "[550]\ttraining's l2: 40719.3\tvalid_1's l2: 54441.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600]\ttraining's l2: 38953.7\tvalid_1's l2: 53190.8\n",
      "[650]\ttraining's l2: 37583.3\tvalid_1's l2: 52255.5\n",
      "[700]\ttraining's l2: 36430.6\tvalid_1's l2: 51719.2\n",
      "[750]\ttraining's l2: 35264.7\tvalid_1's l2: 51106.1\n",
      "[800]\ttraining's l2: 34133\tvalid_1's l2: 50435.5\n",
      "[850]\ttraining's l2: 33192.5\tvalid_1's l2: 49860.6\n",
      "[900]\ttraining's l2: 32396.9\tvalid_1's l2: 49531.2\n",
      "[950]\ttraining's l2: 31595.8\tvalid_1's l2: 49101.6\n",
      "[1000]\ttraining's l2: 30759.4\tvalid_1's l2: 48664.3\n",
      "[1050]\ttraining's l2: 29840.9\tvalid_1's l2: 48266.9\n",
      "[1100]\ttraining's l2: 28981.3\tvalid_1's l2: 47764.9\n",
      "[1150]\ttraining's l2: 28264.5\tvalid_1's l2: 47415.1\n",
      "[1200]\ttraining's l2: 27741.2\tvalid_1's l2: 47162\n",
      "[1250]\ttraining's l2: 27073.2\tvalid_1's l2: 46883.2\n",
      "[1300]\ttraining's l2: 26526.4\tvalid_1's l2: 46692.2\n",
      "[1350]\ttraining's l2: 26083.1\tvalid_1's l2: 46416.9\n",
      "[1400]\ttraining's l2: 25493.7\tvalid_1's l2: 46080.6\n",
      "[1450]\ttraining's l2: 24996.7\tvalid_1's l2: 45824.7\n",
      "[1500]\ttraining's l2: 24547.6\tvalid_1's l2: 45647.4\n",
      "[1550]\ttraining's l2: 24065.4\tvalid_1's l2: 45324.6\n",
      "[1600]\ttraining's l2: 23628.5\tvalid_1's l2: 45117.7\n",
      "[1650]\ttraining's l2: 23193.1\tvalid_1's l2: 44928.8\n",
      "[1700]\ttraining's l2: 22775.1\tvalid_1's l2: 44675.9\n",
      "[1750]\ttraining's l2: 22383.9\tvalid_1's l2: 44492.1\n",
      "[1800]\ttraining's l2: 22004\tvalid_1's l2: 44350.1\n",
      "[1850]\ttraining's l2: 21725.7\tvalid_1's l2: 44239.2\n",
      "[1900]\ttraining's l2: 21338.2\tvalid_1's l2: 44113.7\n",
      "[1950]\ttraining's l2: 20955.5\tvalid_1's l2: 43969.9\n",
      "[2000]\ttraining's l2: 20634.8\tvalid_1's l2: 43910.4\n",
      "[2050]\ttraining's l2: 20306.3\tvalid_1's l2: 43716.8\n",
      "[2100]\ttraining's l2: 19957.7\tvalid_1's l2: 43573.2\n",
      "[2150]\ttraining's l2: 19650.8\tvalid_1's l2: 43487.1\n",
      "[2200]\ttraining's l2: 19360.6\tvalid_1's l2: 43375\n",
      "[2250]\ttraining's l2: 19079.6\tvalid_1's l2: 43370.7\n",
      "Early stopping, best iteration is:\n",
      "[2224]\ttraining's l2: 19246.5\tvalid_1's l2: 43353.1\n",
      "\n",
      " ================== Fold 5 ==================\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttraining's l2: 124298\tvalid_1's l2: 133053\n",
      "[100]\ttraining's l2: 85408.1\tvalid_1's l2: 95215.5\n",
      "[150]\ttraining's l2: 72015.1\tvalid_1's l2: 82599.1\n",
      "[200]\ttraining's l2: 62901.2\tvalid_1's l2: 74003.7\n",
      "[250]\ttraining's l2: 57208.5\tvalid_1's l2: 68833\n",
      "[300]\ttraining's l2: 52715.5\tvalid_1's l2: 65271.6\n",
      "[350]\ttraining's l2: 49181.8\tvalid_1's l2: 62516.3\n",
      "[400]\ttraining's l2: 46236.8\tvalid_1's l2: 60279.7\n",
      "[450]\ttraining's l2: 44005.6\tvalid_1's l2: 58569.7\n",
      "[500]\ttraining's l2: 42129.6\tvalid_1's l2: 57182.3\n",
      "[550]\ttraining's l2: 40081.7\tvalid_1's l2: 55823.2\n",
      "[600]\ttraining's l2: 38370.9\tvalid_1's l2: 54795.4\n",
      "[650]\ttraining's l2: 37033\tvalid_1's l2: 54080.7\n",
      "[700]\ttraining's l2: 35641.2\tvalid_1's l2: 53153.8\n",
      "[750]\ttraining's l2: 34509.4\tvalid_1's l2: 52555.6\n",
      "[800]\ttraining's l2: 33412\tvalid_1's l2: 51972.1\n",
      "[850]\ttraining's l2: 32544\tvalid_1's l2: 51413.3\n",
      "[900]\ttraining's l2: 31662.4\tvalid_1's l2: 51026.8\n",
      "[950]\ttraining's l2: 30741.8\tvalid_1's l2: 50382.3\n",
      "[1000]\ttraining's l2: 30010.8\tvalid_1's l2: 49904.7\n",
      "[1050]\ttraining's l2: 29310.4\tvalid_1's l2: 49439.5\n",
      "[1100]\ttraining's l2: 28681.2\tvalid_1's l2: 49143.2\n",
      "[1150]\ttraining's l2: 28018.2\tvalid_1's l2: 48883\n",
      "[1200]\ttraining's l2: 27558.6\tvalid_1's l2: 48717.6\n",
      "[1250]\ttraining's l2: 27098.6\tvalid_1's l2: 48554.9\n",
      "[1300]\ttraining's l2: 26566.7\tvalid_1's l2: 48331.7\n",
      "[1350]\ttraining's l2: 26117.3\tvalid_1's l2: 48147.8\n",
      "[1400]\ttraining's l2: 25557.2\tvalid_1's l2: 47775.4\n",
      "[1450]\ttraining's l2: 25069.5\tvalid_1's l2: 47472.5\n",
      "[1500]\ttraining's l2: 24511.8\tvalid_1's l2: 47217.8\n",
      "[1550]\ttraining's l2: 24033.7\tvalid_1's l2: 46992.6\n",
      "[1600]\ttraining's l2: 23595\tvalid_1's l2: 46835.8\n",
      "[1650]\ttraining's l2: 23202.5\tvalid_1's l2: 46677.2\n",
      "[1700]\ttraining's l2: 22800.9\tvalid_1's l2: 46477.2\n",
      "[1750]\ttraining's l2: 22457.7\tvalid_1's l2: 46292.6\n",
      "[1800]\ttraining's l2: 22056\tvalid_1's l2: 46126.3\n",
      "[1850]\ttraining's l2: 21689.2\tvalid_1's l2: 46069.5\n",
      "[1900]\ttraining's l2: 21375\tvalid_1's l2: 45955.8\n",
      "[1950]\ttraining's l2: 21042.4\tvalid_1's l2: 45883.6\n",
      "[2000]\ttraining's l2: 20691.3\tvalid_1's l2: 45756.8\n",
      "[2050]\ttraining's l2: 20238.1\tvalid_1's l2: 45565.1\n",
      "Early stopping, best iteration is:\n",
      "[2064]\ttraining's l2: 20153\tvalid_1's l2: 45526.9\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "fold = 1\n",
    "models = {}\n",
    "\n",
    "for train_idx, valid_idx in kfold.split(train):\n",
    "    print('\\n ================== Fold {} =================='.format(fold))\n",
    "\n",
    "    X_train, X_valid = features.iloc[train_idx, :], features.iloc[valid_idx, :]\n",
    "    y_train, y_valid = label.iloc[train_idx, :], label.iloc[valid_idx, :]\n",
    "\n",
    "    model = LGBMRegressor(n_estimators=10000, random_state=0)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_valid, y_valid)], early_stopping_rounds=30, verbose=100)\n",
    "    models[fold] = model\n",
    "\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('energy/sample_submission.csv', encoding='cp949')\n",
    "\n",
    "for i in range(1, 6):\n",
    "    submission['answer'] += models[i].predict(test)/5\n",
    "\n",
    "submission.to_csv('lgbm_day2_3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
