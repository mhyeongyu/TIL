{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d569fcfb1880>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "from numpy.fft import *\n",
    "from scipy import signal, fftpack\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv1D, BatchNormalization, Activation, Dropout\n",
    "from keras.layers import Input, GlobalAveragePooling1D, Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K \n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('./data/train_features.csv')\n",
    "train_labels=pd.read_csv('./data/train_labels.csv')\n",
    "test=pd.read_csv('./data/test_features.csv')\n",
    "\n",
    "submission=pd.read_csv('./data/sample_submission.csv')\n",
    "\n",
    "pd.options.display.max_columns=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engneering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  가속도, 자이로, (자이로-가속도) 센서값을 에너지로 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['acc_Energy']=(train['acc_x']**2+train['acc_y']**2+train['acc_z']**2)**(1/3)\n",
    "test['acc_Energy']=(test['acc_x']**2+test['acc_y']**2+test['acc_z']**2)**(1/3)\n",
    "\n",
    "train['gy_Energy']=(train['gy_x']**2+train['gy_y']**2+train['gy_z']**2)**(1/3)\n",
    "test['gy_Energy']=(test['gy_x']**2+test['gy_y']**2+test['gy_z']**2)**(1/3)\n",
    "\n",
    "train['gy_acc_Energy']=((train['gy_x']-train['acc_x'])**2+(train['gy_y']-train['acc_y'])**2+(train['gy_z']-train['acc_z'])**2)**(1/3)\n",
    "test['gy_acc_Energy']=((test['gy_x']-test['acc_x'])**2+(test['gy_y']-test['acc_y'])**2+(test['gy_z']-test['acc_z'])**2)**(1/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### id별 데이터는 0.02초마다 측정된 값들이기 때문에 이전 시간 대비 변화량 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jerk 가속도변화의 변화량\n",
    "\n",
    "dt=0.02 \n",
    "def jerk_signal(signal): \n",
    "        return np.array([(signal[i+1]-signal[i])/dt for i in range(len(signal)-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3125/3125 [00:58<00:00, 53.62it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dt=[]\n",
    "for i in tqdm(train['id'].unique()):\n",
    "    temp=train.loc[train['id']==i]\n",
    "    for v in train.columns[2:]:\n",
    "        values=jerk_signal(temp[v].values)\n",
    "        values=np.insert(values,0,0)\n",
    "        temp.loc[:,v+'_dt']=values\n",
    "    train_dt.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [00:11<00:00, 70.15it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dt=[]\n",
    "for i in tqdm(test['id'].unique()):\n",
    "    temp=test.loc[test['id']==i]\n",
    "    for v in train.columns[2:]:\n",
    "        values=jerk_signal(temp[v].values)\n",
    "        values=np.insert(values,0,0)\n",
    "        temp.loc[:,v+'_dt']=values\n",
    "    test_dt.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 가속도, 자이로 센서값들을 푸리에 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_transform_one_signal(t_signal):\n",
    "    complex_f_signal= fftpack.fft(t_signal)\n",
    "    amplitude_f_signal=np.abs(complex_f_signal)\n",
    "    return amplitude_f_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3125/3125 [00:13<00:00, 235.98it/s]\n"
     ]
    }
   ],
   "source": [
    "fft=[]\n",
    "for i in tqdm(train['id'].unique()):\n",
    "    temp=train.loc[train['id']==i]\n",
    "    for i in train.columns[2:8]:\n",
    "        temp[i]=fourier_transform_one_signal(temp[i].values)\n",
    "    fft.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 782/782 [00:01<00:00, 421.48it/s]\n"
     ]
    }
   ],
   "source": [
    "fft_t=[]\n",
    "for i in tqdm(test['id'].unique()):\n",
    "    temp=test.loc[test['id']==i]\n",
    "    for i in test.columns[2:8]:\n",
    "        temp[i]=fourier_transform_one_signal(temp[i].values)\n",
    "    fft_t.append(temp)\n",
    "test=pd.concat(fft_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.concat(train_dt)\n",
    "test=pd.concat(test_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Standard scaling 적용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=train.columns\n",
    "train_s=train.copy()\n",
    "test_s=test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "train_s.iloc[:,2:]= scaler.fit_transform(train_s.iloc[:,2:])\n",
    "train_sc = pd.DataFrame(data = train_s,columns =col)\n",
    "\n",
    "test_s.iloc[:,2:]= scaler.transform(test_s.iloc[:,2:])\n",
    "test_sc = pd.DataFrame(data = test_s,columns =col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "      <th>acc_Energy</th>\n",
       "      <th>gy_Energy</th>\n",
       "      <th>gy_acc_Energy</th>\n",
       "      <th>acc_x_dt</th>\n",
       "      <th>acc_y_dt</th>\n",
       "      <th>acc_z_dt</th>\n",
       "      <th>gy_x_dt</th>\n",
       "      <th>gy_y_dt</th>\n",
       "      <th>gy_z_dt</th>\n",
       "      <th>acc_Energy_dt</th>\n",
       "      <th>gy_Energy_dt</th>\n",
       "      <th>gy_acc_Energy_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.356382</td>\n",
       "      <td>8.807207</td>\n",
       "      <td>19.465910</td>\n",
       "      <td>0.376992</td>\n",
       "      <td>0.869226</td>\n",
       "      <td>0.150423</td>\n",
       "      <td>0.495681</td>\n",
       "      <td>-0.272719</td>\n",
       "      <td>-0.276391</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>-0.000433</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.001501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.054866</td>\n",
       "      <td>0.833464</td>\n",
       "      <td>0.820412</td>\n",
       "      <td>-0.282128</td>\n",
       "      <td>-0.093560</td>\n",
       "      <td>0.011266</td>\n",
       "      <td>0.742974</td>\n",
       "      <td>-0.236152</td>\n",
       "      <td>-0.240632</td>\n",
       "      <td>0.416836</td>\n",
       "      <td>-0.118821</td>\n",
       "      <td>-0.255054</td>\n",
       "      <td>0.032738</td>\n",
       "      <td>-0.349095</td>\n",
       "      <td>0.377085</td>\n",
       "      <td>0.564992</td>\n",
       "      <td>0.166566</td>\n",
       "      <td>0.162871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.024046</td>\n",
       "      <td>0.315921</td>\n",
       "      <td>0.081086</td>\n",
       "      <td>-0.182551</td>\n",
       "      <td>-0.053585</td>\n",
       "      <td>-0.003708</td>\n",
       "      <td>0.819822</td>\n",
       "      <td>-0.169815</td>\n",
       "      <td>-0.173080</td>\n",
       "      <td>0.086405</td>\n",
       "      <td>0.023750</td>\n",
       "      <td>-0.531727</td>\n",
       "      <td>-0.141582</td>\n",
       "      <td>-0.202368</td>\n",
       "      <td>-0.004887</td>\n",
       "      <td>0.175645</td>\n",
       "      <td>0.300944</td>\n",
       "      <td>0.306341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.065632</td>\n",
       "      <td>0.117634</td>\n",
       "      <td>-0.040874</td>\n",
       "      <td>-0.194863</td>\n",
       "      <td>0.154242</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>0.785669</td>\n",
       "      <td>-0.035229</td>\n",
       "      <td>-0.040560</td>\n",
       "      <td>-0.058780</td>\n",
       "      <td>-0.213920</td>\n",
       "      <td>0.285459</td>\n",
       "      <td>0.229520</td>\n",
       "      <td>-0.385106</td>\n",
       "      <td>-0.135647</td>\n",
       "      <td>-0.077915</td>\n",
       "      <td>0.609008</td>\n",
       "      <td>0.599518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.151477</td>\n",
       "      <td>0.300751</td>\n",
       "      <td>0.317742</td>\n",
       "      <td>-0.350724</td>\n",
       "      <td>0.494539</td>\n",
       "      <td>0.154354</td>\n",
       "      <td>0.791528</td>\n",
       "      <td>0.021954</td>\n",
       "      <td>0.016872</td>\n",
       "      <td>0.039823</td>\n",
       "      <td>0.259227</td>\n",
       "      <td>-0.055206</td>\n",
       "      <td>0.057320</td>\n",
       "      <td>-0.174917</td>\n",
       "      <td>-0.028047</td>\n",
       "      <td>0.013483</td>\n",
       "      <td>0.259626</td>\n",
       "      <td>0.260669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874995</th>\n",
       "      <td>3124</td>\n",
       "      <td>595</td>\n",
       "      <td>0.365037</td>\n",
       "      <td>0.011656</td>\n",
       "      <td>0.845701</td>\n",
       "      <td>0.080839</td>\n",
       "      <td>0.350395</td>\n",
       "      <td>0.112282</td>\n",
       "      <td>-0.138940</td>\n",
       "      <td>0.829394</td>\n",
       "      <td>0.823900</td>\n",
       "      <td>0.151679</td>\n",
       "      <td>0.037205</td>\n",
       "      <td>0.119409</td>\n",
       "      <td>-0.108728</td>\n",
       "      <td>-0.027804</td>\n",
       "      <td>-0.009085</td>\n",
       "      <td>-0.142794</td>\n",
       "      <td>0.063329</td>\n",
       "      <td>0.063674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874996</th>\n",
       "      <td>3124</td>\n",
       "      <td>596</td>\n",
       "      <td>10.220817</td>\n",
       "      <td>5.476964</td>\n",
       "      <td>7.441373</td>\n",
       "      <td>3.605246</td>\n",
       "      <td>16.530576</td>\n",
       "      <td>11.843241</td>\n",
       "      <td>-0.167578</td>\n",
       "      <td>0.814816</td>\n",
       "      <td>0.809618</td>\n",
       "      <td>0.150658</td>\n",
       "      <td>-0.000363</td>\n",
       "      <td>0.265559</td>\n",
       "      <td>-0.027936</td>\n",
       "      <td>0.090560</td>\n",
       "      <td>-0.018412</td>\n",
       "      <td>-0.065316</td>\n",
       "      <td>-0.064300</td>\n",
       "      <td>-0.062949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874997</th>\n",
       "      <td>3124</td>\n",
       "      <td>597</td>\n",
       "      <td>0.386337</td>\n",
       "      <td>0.177768</td>\n",
       "      <td>-0.080193</td>\n",
       "      <td>-0.192468</td>\n",
       "      <td>-0.033904</td>\n",
       "      <td>-0.227861</td>\n",
       "      <td>-0.151875</td>\n",
       "      <td>0.802027</td>\n",
       "      <td>0.797338</td>\n",
       "      <td>0.093524</td>\n",
       "      <td>-0.049283</td>\n",
       "      <td>0.260884</td>\n",
       "      <td>0.082744</td>\n",
       "      <td>0.123264</td>\n",
       "      <td>-0.152712</td>\n",
       "      <td>0.035970</td>\n",
       "      <td>-0.056225</td>\n",
       "      <td>-0.053918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874998</th>\n",
       "      <td>3124</td>\n",
       "      <td>598</td>\n",
       "      <td>0.728823</td>\n",
       "      <td>0.014037</td>\n",
       "      <td>0.350745</td>\n",
       "      <td>0.136284</td>\n",
       "      <td>1.281790</td>\n",
       "      <td>0.403540</td>\n",
       "      <td>-0.175811</td>\n",
       "      <td>0.801880</td>\n",
       "      <td>0.797431</td>\n",
       "      <td>0.174681</td>\n",
       "      <td>-0.096564</td>\n",
       "      <td>0.071332</td>\n",
       "      <td>0.153722</td>\n",
       "      <td>-0.014412</td>\n",
       "      <td>-0.049662</td>\n",
       "      <td>-0.054574</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.001922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874999</th>\n",
       "      <td>3124</td>\n",
       "      <td>599</td>\n",
       "      <td>0.886204</td>\n",
       "      <td>0.075614</td>\n",
       "      <td>1.107553</td>\n",
       "      <td>-0.182228</td>\n",
       "      <td>0.894062</td>\n",
       "      <td>0.311408</td>\n",
       "      <td>-0.223043</td>\n",
       "      <td>0.803421</td>\n",
       "      <td>0.799233</td>\n",
       "      <td>0.266539</td>\n",
       "      <td>-0.107081</td>\n",
       "      <td>0.079654</td>\n",
       "      <td>0.207388</td>\n",
       "      <td>-0.042034</td>\n",
       "      <td>-0.022996</td>\n",
       "      <td>-0.107792</td>\n",
       "      <td>0.008458</td>\n",
       "      <td>0.009633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1875000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  time      acc_x     acc_y      acc_z      gy_x       gy_y  \\\n",
       "0           0     0  27.356382  8.807207  19.465910  0.376992   0.869226   \n",
       "1           0     1  -0.054866  0.833464   0.820412 -0.282128  -0.093560   \n",
       "2           0     2   0.024046  0.315921   0.081086 -0.182551  -0.053585   \n",
       "3           0     3   0.065632  0.117634  -0.040874 -0.194863   0.154242   \n",
       "4           0     4   0.151477  0.300751   0.317742 -0.350724   0.494539   \n",
       "...       ...   ...        ...       ...        ...       ...        ...   \n",
       "1874995  3124   595   0.365037  0.011656   0.845701  0.080839   0.350395   \n",
       "1874996  3124   596  10.220817  5.476964   7.441373  3.605246  16.530576   \n",
       "1874997  3124   597   0.386337  0.177768  -0.080193 -0.192468  -0.033904   \n",
       "1874998  3124   598   0.728823  0.014037   0.350745  0.136284   1.281790   \n",
       "1874999  3124   599   0.886204  0.075614   1.107553 -0.182228   0.894062   \n",
       "\n",
       "              gy_z  acc_Energy  gy_Energy  gy_acc_Energy  acc_x_dt  acc_y_dt  \\\n",
       "0         0.150423    0.495681  -0.272719      -0.276391  0.000027  0.000298   \n",
       "1         0.011266    0.742974  -0.236152      -0.240632  0.416836 -0.118821   \n",
       "2        -0.003708    0.819822  -0.169815      -0.173080  0.086405  0.023750   \n",
       "3         0.005408    0.785669  -0.035229      -0.040560 -0.058780 -0.213920   \n",
       "4         0.154354    0.791528   0.021954       0.016872  0.039823  0.259227   \n",
       "...            ...         ...        ...            ...       ...       ...   \n",
       "1874995   0.112282   -0.138940   0.829394       0.823900  0.151679  0.037205   \n",
       "1874996  11.843241   -0.167578   0.814816       0.809618  0.150658 -0.000363   \n",
       "1874997  -0.227861   -0.151875   0.802027       0.797338  0.093524 -0.049283   \n",
       "1874998   0.403540   -0.175811   0.801880       0.797431  0.174681 -0.096564   \n",
       "1874999   0.311408   -0.223043   0.803421       0.799233  0.266539 -0.107081   \n",
       "\n",
       "         acc_z_dt   gy_x_dt   gy_y_dt   gy_z_dt  acc_Energy_dt  gy_Energy_dt  \\\n",
       "0       -0.000433  0.000347  0.000373  0.000273       0.000101      0.001505   \n",
       "1       -0.255054  0.032738 -0.349095  0.377085       0.564992      0.166566   \n",
       "2       -0.531727 -0.141582 -0.202368 -0.004887       0.175645      0.300944   \n",
       "3        0.285459  0.229520 -0.385106 -0.135647      -0.077915      0.609008   \n",
       "4       -0.055206  0.057320 -0.174917 -0.028047       0.013483      0.259626   \n",
       "...           ...       ...       ...       ...            ...           ...   \n",
       "1874995  0.119409 -0.108728 -0.027804 -0.009085      -0.142794      0.063329   \n",
       "1874996  0.265559 -0.027936  0.090560 -0.018412      -0.065316     -0.064300   \n",
       "1874997  0.260884  0.082744  0.123264 -0.152712       0.035970     -0.056225   \n",
       "1874998  0.071332  0.153722 -0.014412 -0.049662      -0.054574      0.000843   \n",
       "1874999  0.079654  0.207388 -0.042034 -0.022996      -0.107792      0.008458   \n",
       "\n",
       "         gy_acc_Energy_dt  \n",
       "0                0.001501  \n",
       "1                0.162871  \n",
       "2                0.306341  \n",
       "3                0.599518  \n",
       "4                0.260669  \n",
       "...                   ...  \n",
       "1874995          0.063674  \n",
       "1874996         -0.062949  \n",
       "1874997         -0.053918  \n",
       "1874998          0.001922  \n",
       "1874999          0.009633  \n",
       "\n",
       "[1875000 rows x 20 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 모델링\n",
    "\n",
    "+ CNN, LSTM, CNN+LSTM 등 여러 구조 적용해보다가 CNN에서 Flatten 없이 Global average pooling 한 구조가 가장 성능이 좋아 채택했습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3125, 600, 18)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.array(train_sc.iloc[:,2:]).reshape(3125, 600, -1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(782, 600, 18)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x=np.array(test_sc.iloc[:,2:]).reshape(782, 600, -1)\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3125, 61)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train_labels['label'].values\n",
    "y = tf.keras.utils.to_categorical(train_labels['label']) \n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 모델 구조 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(input_shape, classes):\n",
    "    seed(2021)\n",
    "    tf.random.set_seed(2021)\n",
    "    \n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    conv1 = keras.layers.Conv1D(filters=128, kernel_size=9, padding='same')(input_layer)\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = keras.layers.Activation(activation='relu')(conv1)\n",
    "    conv1 = keras.layers.Dropout(rate=0.3)(conv1)\n",
    "\n",
    "    conv2 = keras.layers.Conv1D(filters=256, kernel_size=6, padding='same')(conv1)\n",
    "    conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = keras.layers.Activation('relu')(conv2)\n",
    "    conv2 = keras.layers.Dropout(rate=0.4)(conv2)\n",
    "    \n",
    "    conv3 = keras.layers.Conv1D(128, kernel_size=3,padding='same')(conv2)\n",
    "    conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = keras.layers.Activation('relu')(conv3)\n",
    "    conv3 = keras.layers.Dropout(rate=0.5)(conv3)\n",
    "    \n",
    "    gap = keras.layers.GlobalAveragePooling1D()(conv3)\n",
    "    \n",
    "    output_layer = keras.layers.Dense(classes, activation='softmax')(gap)\n",
    "    \n",
    "    model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer = keras.optimizers.Adam(), \n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10-fold StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Fold_1--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 9s 185ms/step - loss: 3.3854 - accuracy: 0.3490 - val_loss: 3.1161 - val_accuracy: 0.3099\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 8s 185ms/step - loss: 1.9729 - accuracy: 0.5509 - val_loss: 1.9228 - val_accuracy: 0.5304\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 8s 185ms/step - loss: 1.7849 - accuracy: 0.5650 - val_loss: 2.0362 - val_accuracy: 0.5495\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 1.5552 - accuracy: 0.6141 - val_loss: 1.9158 - val_accuracy: 0.5623\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 1.3835 - accuracy: 0.6450 - val_loss: 1.5137 - val_accuracy: 0.6070\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 1.2684 - accuracy: 0.6751 - val_loss: 1.4040 - val_accuracy: 0.6230\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 1.1646 - accuracy: 0.6891 - val_loss: 1.2561 - val_accuracy: 0.6550\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 1.0603 - accuracy: 0.7168 - val_loss: 1.1957 - val_accuracy: 0.6773\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.9702 - accuracy: 0.7390 - val_loss: 1.1095 - val_accuracy: 0.7093\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.9055 - accuracy: 0.7567 - val_loss: 0.9851 - val_accuracy: 0.7572\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.8772 - accuracy: 0.7569 - val_loss: 0.9508 - val_accuracy: 0.7732\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.7877 - accuracy: 0.7860 - val_loss: 1.1010 - val_accuracy: 0.7316\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.7497 - accuracy: 0.7816 - val_loss: 0.9534 - val_accuracy: 0.7732\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.7095 - accuracy: 0.8003 - val_loss: 0.8475 - val_accuracy: 0.7732\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.6783 - accuracy: 0.8029 - val_loss: 0.7799 - val_accuracy: 0.8083\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.6177 - accuracy: 0.8349 - val_loss: 0.7713 - val_accuracy: 0.8179\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.5864 - accuracy: 0.8382 - val_loss: 0.7485 - val_accuracy: 0.7891\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.5729 - accuracy: 0.8265 - val_loss: 0.7256 - val_accuracy: 0.8083\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.5377 - accuracy: 0.8494 - val_loss: 0.7081 - val_accuracy: 0.8051\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.4999 - accuracy: 0.8579 - val_loss: 0.6763 - val_accuracy: 0.8051\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.5073 - accuracy: 0.8556 - val_loss: 0.7458 - val_accuracy: 0.8147\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.4766 - accuracy: 0.8569 - val_loss: 0.6444 - val_accuracy: 0.8019\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.4479 - accuracy: 0.8716 - val_loss: 0.6840 - val_accuracy: 0.7955\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.4305 - accuracy: 0.8771 - val_loss: 0.6818 - val_accuracy: 0.8211\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.4523 - accuracy: 0.8773 - val_loss: 0.6613 - val_accuracy: 0.8115\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 8s 178ms/step - loss: 0.4024 - accuracy: 0.8820 - val_loss: 0.7498 - val_accuracy: 0.7764\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.3788 - accuracy: 0.8973 - val_loss: 0.6059 - val_accuracy: 0.8307\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.3580 - accuracy: 0.9026 - val_loss: 0.6103 - val_accuracy: 0.8307\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.3496 - accuracy: 0.8991 - val_loss: 0.6190 - val_accuracy: 0.8211\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.3652 - accuracy: 0.9048 - val_loss: 0.5941 - val_accuracy: 0.8211\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.3484 - accuracy: 0.9052 - val_loss: 0.6028 - val_accuracy: 0.8339\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.3325 - accuracy: 0.9054 - val_loss: 0.5876 - val_accuracy: 0.8371\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.3063 - accuracy: 0.9182 - val_loss: 0.6011 - val_accuracy: 0.8179\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3194 - accuracy: 0.9144 - val_loss: 0.5761 - val_accuracy: 0.8339\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.3116 - accuracy: 0.9118 - val_loss: 0.6350 - val_accuracy: 0.8243\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.3211 - accuracy: 0.9072 - val_loss: 0.5904 - val_accuracy: 0.8275\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3028 - accuracy: 0.9183 - val_loss: 0.5898 - val_accuracy: 0.8371\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 8s 185ms/step - loss: 0.2931 - accuracy: 0.9176 - val_loss: 0.5957 - val_accuracy: 0.8211\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2801 - accuracy: 0.9305 - val_loss: 0.5583 - val_accuracy: 0.8403\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2811 - accuracy: 0.9214 - val_loss: 0.5523 - val_accuracy: 0.8562\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2610 - accuracy: 0.9373 - val_loss: 0.5557 - val_accuracy: 0.8371\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2750 - accuracy: 0.9306 - val_loss: 0.5534 - val_accuracy: 0.8530\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2767 - accuracy: 0.9286 - val_loss: 0.5693 - val_accuracy: 0.8339\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2533 - accuracy: 0.9424 - val_loss: 0.5564 - val_accuracy: 0.8466\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2422 - accuracy: 0.9414 - val_loss: 0.5611 - val_accuracy: 0.8435\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2499 - accuracy: 0.9401 - val_loss: 0.5546 - val_accuracy: 0.8435\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2555 - accuracy: 0.9397 - val_loss: 0.5453 - val_accuracy: 0.8466\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2540 - accuracy: 0.9354 - val_loss: 0.5480 - val_accuracy: 0.8435\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2461 - accuracy: 0.9341 - val_loss: 0.5491 - val_accuracy: 0.8403\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2496 - accuracy: 0.9324 - val_loss: 0.5485 - val_accuracy: 0.8339\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2358 - accuracy: 0.9444 - val_loss: 0.5484 - val_accuracy: 0.8498\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2754 - accuracy: 0.9279 - val_loss: 0.5412 - val_accuracy: 0.8466\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2346 - accuracy: 0.9443 - val_loss: 0.5386 - val_accuracy: 0.8530\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2356 - accuracy: 0.9446 - val_loss: 0.5421 - val_accuracy: 0.8466\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.2563 - accuracy: 0.9405 - val_loss: 0.5407 - val_accuracy: 0.8435\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2562 - accuracy: 0.9359 - val_loss: 0.5375 - val_accuracy: 0.8466\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2383 - accuracy: 0.9392 - val_loss: 0.5416 - val_accuracy: 0.8498\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.2440 - accuracy: 0.9389 - val_loss: 0.5423 - val_accuracy: 0.8498\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2208 - accuracy: 0.9490 - val_loss: 0.5383 - val_accuracy: 0.8466\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2503 - accuracy: 0.9347 - val_loss: 0.5397 - val_accuracy: 0.8562\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2480 - accuracy: 0.9395 - val_loss: 0.5383 - val_accuracy: 0.8466\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2378 - accuracy: 0.9472 - val_loss: 0.5382 - val_accuracy: 0.8466\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2290 - accuracy: 0.9416 - val_loss: 0.5374 - val_accuracy: 0.8435\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.2339 - accuracy: 0.9422 - val_loss: 0.5380 - val_accuracy: 0.8530\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2181 - accuracy: 0.9483 - val_loss: 0.5376 - val_accuracy: 0.8530\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2257 - accuracy: 0.9516 - val_loss: 0.5380 - val_accuracy: 0.8498\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2389 - accuracy: 0.9484 - val_loss: 0.5388 - val_accuracy: 0.8498\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2349 - accuracy: 0.9403 - val_loss: 0.5367 - val_accuracy: 0.8530\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2331 - accuracy: 0.9515 - val_loss: 0.5369 - val_accuracy: 0.8498\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2231 - accuracy: 0.9447 - val_loss: 0.5368 - val_accuracy: 0.8498\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2284 - accuracy: 0.9447 - val_loss: 0.5377 - val_accuracy: 0.8498\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2134 - accuracy: 0.9516 - val_loss: 0.5371 - val_accuracy: 0.8562\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2547 - accuracy: 0.9403 - val_loss: 0.5374 - val_accuracy: 0.8530\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2351 - accuracy: 0.9413 - val_loss: 0.5372 - val_accuracy: 0.8498\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2234 - accuracy: 0.9460 - val_loss: 0.5364 - val_accuracy: 0.8530\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2282 - accuracy: 0.9344 - val_loss: 0.5362 - val_accuracy: 0.8530\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2287 - accuracy: 0.9387 - val_loss: 0.5366 - val_accuracy: 0.8562\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2490 - accuracy: 0.9350 - val_loss: 0.5372 - val_accuracy: 0.8498\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2233 - accuracy: 0.9461 - val_loss: 0.5365 - val_accuracy: 0.8498\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2231 - accuracy: 0.9430 - val_loss: 0.5368 - val_accuracy: 0.8466\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2360 - accuracy: 0.9453 - val_loss: 0.5365 - val_accuracy: 0.8466\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2301 - accuracy: 0.9430 - val_loss: 0.5364 - val_accuracy: 0.8466\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2491 - accuracy: 0.9348 - val_loss: 0.5363 - val_accuracy: 0.8562\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2242 - accuracy: 0.9492 - val_loss: 0.5361 - val_accuracy: 0.8530\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2314 - accuracy: 0.9452 - val_loss: 0.5362 - val_accuracy: 0.8562\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2424 - accuracy: 0.9401 - val_loss: 0.5358 - val_accuracy: 0.8562\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2344 - accuracy: 0.9421 - val_loss: 0.5358 - val_accuracy: 0.8498\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2440 - accuracy: 0.9402 - val_loss: 0.5354 - val_accuracy: 0.8530\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2208 - accuracy: 0.9478 - val_loss: 0.5350 - val_accuracy: 0.8562\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.2139 - accuracy: 0.9511 - val_loss: 0.5355 - val_accuracy: 0.8594\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2120 - accuracy: 0.9487 - val_loss: 0.5360 - val_accuracy: 0.8530\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2451 - accuracy: 0.9394 - val_loss: 0.5361 - val_accuracy: 0.8530\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2361 - accuracy: 0.9440 - val_loss: 0.5362 - val_accuracy: 0.8530\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2450 - accuracy: 0.9396 - val_loss: 0.5362 - val_accuracy: 0.8562\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2265 - accuracy: 0.9500 - val_loss: 0.5360 - val_accuracy: 0.8530\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2161 - accuracy: 0.9508 - val_loss: 0.5359 - val_accuracy: 0.8562\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2201 - accuracy: 0.9533 - val_loss: 0.5360 - val_accuracy: 0.8498\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5350 - accuracy: 0.8562\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5350 - accuracy: 0.8562\n",
      "--------------------Fold_2--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 9s 185ms/step - loss: 3.4087 - accuracy: 0.3354 - val_loss: 3.2235 - val_accuracy: 0.3099\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 2.0135 - accuracy: 0.5430 - val_loss: 1.8948 - val_accuracy: 0.5431\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 1.7351 - accuracy: 0.5815 - val_loss: 1.9706 - val_accuracy: 0.5431\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 1.5307 - accuracy: 0.6188 - val_loss: 1.6252 - val_accuracy: 0.5751\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 1.4244 - accuracy: 0.6295 - val_loss: 1.5192 - val_accuracy: 0.6006\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 8s 185ms/step - loss: 1.2449 - accuracy: 0.6791 - val_loss: 1.4169 - val_accuracy: 0.6166\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 8s 185ms/step - loss: 1.1708 - accuracy: 0.6863 - val_loss: 1.3115 - val_accuracy: 0.6486\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 1.1031 - accuracy: 0.7061 - val_loss: 1.2211 - val_accuracy: 0.6741\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 1.0043 - accuracy: 0.7249 - val_loss: 1.0456 - val_accuracy: 0.7284\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 8s 185ms/step - loss: 0.9419 - accuracy: 0.7443 - val_loss: 0.9392 - val_accuracy: 0.7827\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.8386 - accuracy: 0.7699 - val_loss: 0.8931 - val_accuracy: 0.7508\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.7998 - accuracy: 0.7750 - val_loss: 0.8766 - val_accuracy: 0.7540\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.7521 - accuracy: 0.7948 - val_loss: 0.7987 - val_accuracy: 0.7604\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.7254 - accuracy: 0.7906 - val_loss: 0.7729 - val_accuracy: 0.7955\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 8s 186ms/step - loss: 0.6685 - accuracy: 0.8101 - val_loss: 0.7397 - val_accuracy: 0.7827\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.6274 - accuracy: 0.8190 - val_loss: 0.8465 - val_accuracy: 0.7955\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.6117 - accuracy: 0.8322 - val_loss: 0.6865 - val_accuracy: 0.7955\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.5728 - accuracy: 0.8383 - val_loss: 0.6846 - val_accuracy: 0.8211\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.5298 - accuracy: 0.8597 - val_loss: 0.6226 - val_accuracy: 0.8211\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.5011 - accuracy: 0.8489 - val_loss: 0.6331 - val_accuracy: 0.8147\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.4866 - accuracy: 0.8646 - val_loss: 0.6286 - val_accuracy: 0.8339\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.4680 - accuracy: 0.8746 - val_loss: 0.6417 - val_accuracy: 0.8275\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.4753 - accuracy: 0.8648 - val_loss: 0.6173 - val_accuracy: 0.8115\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.4288 - accuracy: 0.8803 - val_loss: 0.6333 - val_accuracy: 0.7923\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 8s 188ms/step - loss: 0.4296 - accuracy: 0.8705 - val_loss: 0.6220 - val_accuracy: 0.8147\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.4099 - accuracy: 0.8836 - val_loss: 0.6293 - val_accuracy: 0.8083\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.4127 - accuracy: 0.8866 - val_loss: 0.5709 - val_accuracy: 0.8051\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.4006 - accuracy: 0.8891 - val_loss: 0.5567 - val_accuracy: 0.8403\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 8s 185ms/step - loss: 0.3776 - accuracy: 0.8888 - val_loss: 0.5581 - val_accuracy: 0.8307\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.3808 - accuracy: 0.8930 - val_loss: 0.5948 - val_accuracy: 0.8275\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 8s 185ms/step - loss: 0.3598 - accuracy: 0.9034 - val_loss: 0.5556 - val_accuracy: 0.8243\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.3411 - accuracy: 0.8982 - val_loss: 0.6639 - val_accuracy: 0.7891\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.3480 - accuracy: 0.8964 - val_loss: 0.5686 - val_accuracy: 0.8275\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 8s 185ms/step - loss: 0.3155 - accuracy: 0.9131 - val_loss: 0.5616 - val_accuracy: 0.8403\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 8s 185ms/step - loss: 0.3155 - accuracy: 0.9220 - val_loss: 0.5170 - val_accuracy: 0.8403\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3247 - accuracy: 0.9141 - val_loss: 0.5410 - val_accuracy: 0.8403\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.3020 - accuracy: 0.9159 - val_loss: 0.5532 - val_accuracy: 0.8211\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3131 - accuracy: 0.9052 - val_loss: 0.5720 - val_accuracy: 0.8243\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2854 - accuracy: 0.9204 - val_loss: 0.5679 - val_accuracy: 0.8115\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2832 - accuracy: 0.9213 - val_loss: 0.5431 - val_accuracy: 0.8243\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2679 - accuracy: 0.9200 - val_loss: 0.5185 - val_accuracy: 0.8371\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2805 - accuracy: 0.9242 - val_loss: 0.5026 - val_accuracy: 0.8339\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2378 - accuracy: 0.9424 - val_loss: 0.5049 - val_accuracy: 0.8307\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2617 - accuracy: 0.9250 - val_loss: 0.5113 - val_accuracy: 0.8403\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2568 - accuracy: 0.9312 - val_loss: 0.5401 - val_accuracy: 0.8307\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.2419 - accuracy: 0.9366 - val_loss: 0.5186 - val_accuracy: 0.8403\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2356 - accuracy: 0.9427 - val_loss: 0.4889 - val_accuracy: 0.8530\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2099 - accuracy: 0.9500 - val_loss: 0.4758 - val_accuracy: 0.8466\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2376 - accuracy: 0.9379 - val_loss: 0.4826 - val_accuracy: 0.8562\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.2010 - accuracy: 0.9500 - val_loss: 0.5051 - val_accuracy: 0.8371\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2085 - accuracy: 0.9518 - val_loss: 0.4931 - val_accuracy: 0.8371\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.2029 - accuracy: 0.9488 - val_loss: 0.4882 - val_accuracy: 0.8530\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.1980 - accuracy: 0.9525 - val_loss: 0.4832 - val_accuracy: 0.8466\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.1844 - accuracy: 0.9590 - val_loss: 0.4919 - val_accuracy: 0.8435\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.1980 - accuracy: 0.9522 - val_loss: 0.4759 - val_accuracy: 0.8498\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.1919 - accuracy: 0.9563 - val_loss: 0.4871 - val_accuracy: 0.8466\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4758 - accuracy: 0.8466\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4758 - accuracy: 0.8466\n",
      "--------------------Fold_3--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 9s 187ms/step - loss: 3.3707 - accuracy: 0.3413 - val_loss: 3.1703 - val_accuracy: 0.3323\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 8s 185ms/step - loss: 1.9793 - accuracy: 0.5496 - val_loss: 1.8589 - val_accuracy: 0.5527\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 1.7007 - accuracy: 0.5952 - val_loss: 1.7976 - val_accuracy: 0.5527\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 1.5332 - accuracy: 0.6167 - val_loss: 1.5757 - val_accuracy: 0.5751\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 1.3839 - accuracy: 0.6454 - val_loss: 1.5885 - val_accuracy: 0.6070\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 1.2320 - accuracy: 0.6813 - val_loss: 1.3246 - val_accuracy: 0.6326\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 1.1608 - accuracy: 0.6954 - val_loss: 1.1648 - val_accuracy: 0.6901\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 1.0542 - accuracy: 0.7217 - val_loss: 1.0786 - val_accuracy: 0.7220\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 1.0407 - accuracy: 0.7128 - val_loss: 1.0472 - val_accuracy: 0.7380\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.8956 - accuracy: 0.7591 - val_loss: 0.9337 - val_accuracy: 0.7508\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.8656 - accuracy: 0.7490 - val_loss: 0.9020 - val_accuracy: 0.7764\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.7914 - accuracy: 0.7917 - val_loss: 0.8772 - val_accuracy: 0.7796\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.7463 - accuracy: 0.7862 - val_loss: 0.7643 - val_accuracy: 0.7955\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.7211 - accuracy: 0.7968 - val_loss: 0.7634 - val_accuracy: 0.7764\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.6327 - accuracy: 0.8098 - val_loss: 0.7711 - val_accuracy: 0.7732\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.6020 - accuracy: 0.8289 - val_loss: 0.7412 - val_accuracy: 0.7827\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.6137 - accuracy: 0.8178 - val_loss: 0.7279 - val_accuracy: 0.7955\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.5618 - accuracy: 0.8358 - val_loss: 0.6913 - val_accuracy: 0.8115\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.5359 - accuracy: 0.8587 - val_loss: 0.6123 - val_accuracy: 0.8339\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.5035 - accuracy: 0.8522 - val_loss: 0.6428 - val_accuracy: 0.8243\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 8s 185ms/step - loss: 0.4999 - accuracy: 0.8540 - val_loss: 0.6539 - val_accuracy: 0.8498\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.4630 - accuracy: 0.8726 - val_loss: 0.6243 - val_accuracy: 0.8211\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.4761 - accuracy: 0.8609 - val_loss: 0.5717 - val_accuracy: 0.8211\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.4630 - accuracy: 0.8621 - val_loss: 0.5867 - val_accuracy: 0.8371\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.4230 - accuracy: 0.8709 - val_loss: 0.5808 - val_accuracy: 0.8147\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.4008 - accuracy: 0.8808 - val_loss: 0.5329 - val_accuracy: 0.8530\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.4312 - accuracy: 0.8709 - val_loss: 0.5058 - val_accuracy: 0.8498\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.3935 - accuracy: 0.8863 - val_loss: 0.5552 - val_accuracy: 0.8339\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 8s 185ms/step - loss: 0.3774 - accuracy: 0.8904 - val_loss: 0.5389 - val_accuracy: 0.8339\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 8s 185ms/step - loss: 0.3765 - accuracy: 0.8887 - val_loss: 0.6882 - val_accuracy: 0.7891\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 8s 189ms/step - loss: 0.3775 - accuracy: 0.8885 - val_loss: 0.5027 - val_accuracy: 0.8339\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 8s 185ms/step - loss: 0.3447 - accuracy: 0.9050 - val_loss: 0.5355 - val_accuracy: 0.8498\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.3496 - accuracy: 0.8972 - val_loss: 0.5862 - val_accuracy: 0.8115\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.3453 - accuracy: 0.8954 - val_loss: 0.6494 - val_accuracy: 0.8051\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3640 - accuracy: 0.8975 - val_loss: 0.5230 - val_accuracy: 0.8498\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2908 - accuracy: 0.9207 - val_loss: 0.4986 - val_accuracy: 0.8339\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.2750 - accuracy: 0.9285 - val_loss: 0.4826 - val_accuracy: 0.8403\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2764 - accuracy: 0.9203 - val_loss: 0.4692 - val_accuracy: 0.8466\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2670 - accuracy: 0.9243 - val_loss: 0.4576 - val_accuracy: 0.8466\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.2723 - accuracy: 0.9171 - val_loss: 0.4698 - val_accuracy: 0.8594\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2759 - accuracy: 0.9263 - val_loss: 0.4611 - val_accuracy: 0.8562\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2813 - accuracy: 0.9179 - val_loss: 0.4983 - val_accuracy: 0.8403\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2715 - accuracy: 0.9326 - val_loss: 0.4953 - val_accuracy: 0.8403\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.2428 - accuracy: 0.9357 - val_loss: 0.4471 - val_accuracy: 0.8498\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.2364 - accuracy: 0.9393 - val_loss: 0.4531 - val_accuracy: 0.8594\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.2424 - accuracy: 0.9323 - val_loss: 0.4456 - val_accuracy: 0.8562\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 8s 185ms/step - loss: 0.2274 - accuracy: 0.9403 - val_loss: 0.4389 - val_accuracy: 0.8498\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.2398 - accuracy: 0.9371 - val_loss: 0.4363 - val_accuracy: 0.8626\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 8s 186ms/step - loss: 0.2291 - accuracy: 0.9438 - val_loss: 0.4325 - val_accuracy: 0.8658\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 8s 186ms/step - loss: 0.2295 - accuracy: 0.9362 - val_loss: 0.4354 - val_accuracy: 0.8658\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.2243 - accuracy: 0.9385 - val_loss: 0.4489 - val_accuracy: 0.8530\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.2577 - accuracy: 0.9284 - val_loss: 0.4308 - val_accuracy: 0.8626\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 8s 185ms/step - loss: 0.2270 - accuracy: 0.9383 - val_loss: 0.4364 - val_accuracy: 0.8498\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2430 - accuracy: 0.9327 - val_loss: 0.4508 - val_accuracy: 0.8466\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2189 - accuracy: 0.9462 - val_loss: 0.4331 - val_accuracy: 0.8658\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2236 - accuracy: 0.9396 - val_loss: 0.4307 - val_accuracy: 0.8594\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2248 - accuracy: 0.9387 - val_loss: 0.4437 - val_accuracy: 0.8562\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2135 - accuracy: 0.9402 - val_loss: 0.4482 - val_accuracy: 0.8594\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2162 - accuracy: 0.9399 - val_loss: 0.4335 - val_accuracy: 0.8594\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2263 - accuracy: 0.9412 - val_loss: 0.4398 - val_accuracy: 0.8626\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.1910 - accuracy: 0.9524 - val_loss: 0.4310 - val_accuracy: 0.8594\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2102 - accuracy: 0.9418 - val_loss: 0.4277 - val_accuracy: 0.8626\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2097 - accuracy: 0.9498 - val_loss: 0.4274 - val_accuracy: 0.8594\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.1766 - accuracy: 0.9544 - val_loss: 0.4246 - val_accuracy: 0.8690\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2054 - accuracy: 0.9526 - val_loss: 0.4281 - val_accuracy: 0.8722\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2100 - accuracy: 0.9511 - val_loss: 0.4312 - val_accuracy: 0.8626\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.1923 - accuracy: 0.9466 - val_loss: 0.4374 - val_accuracy: 0.8626\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.1891 - accuracy: 0.9556 - val_loss: 0.4293 - val_accuracy: 0.8626\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.1789 - accuracy: 0.9521 - val_loss: 0.4256 - val_accuracy: 0.8690\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.1929 - accuracy: 0.9507 - val_loss: 0.4231 - val_accuracy: 0.8626\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.1800 - accuracy: 0.9566 - val_loss: 0.4249 - val_accuracy: 0.8658\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.1862 - accuracy: 0.9520 - val_loss: 0.4206 - val_accuracy: 0.8658\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.1891 - accuracy: 0.9561 - val_loss: 0.4212 - val_accuracy: 0.8626\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.1877 - accuracy: 0.9607 - val_loss: 0.4204 - val_accuracy: 0.8690\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 8s 186ms/step - loss: 0.1918 - accuracy: 0.9479 - val_loss: 0.4192 - val_accuracy: 0.8722\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.1799 - accuracy: 0.9487 - val_loss: 0.4199 - val_accuracy: 0.8658\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.1848 - accuracy: 0.9539 - val_loss: 0.4212 - val_accuracy: 0.8626\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.1967 - accuracy: 0.9463 - val_loss: 0.4224 - val_accuracy: 0.8594\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.1709 - accuracy: 0.9638 - val_loss: 0.4195 - val_accuracy: 0.8626\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.1849 - accuracy: 0.9563 - val_loss: 0.4214 - val_accuracy: 0.8690\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.1910 - accuracy: 0.9533 - val_loss: 0.4207 - val_accuracy: 0.8690\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.1838 - accuracy: 0.9545 - val_loss: 0.4208 - val_accuracy: 0.8690\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.1830 - accuracy: 0.9552 - val_loss: 0.4215 - val_accuracy: 0.8626\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4192 - accuracy: 0.8722\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4192 - accuracy: 0.8722\n",
      "--------------------Fold_4--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 9s 183ms/step - loss: 3.3705 - accuracy: 0.3537 - val_loss: 3.0873 - val_accuracy: 0.3642\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 1.9608 - accuracy: 0.5554 - val_loss: 1.9848 - val_accuracy: 0.5431\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 1.7312 - accuracy: 0.5809 - val_loss: 1.9145 - val_accuracy: 0.5367\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 1.5519 - accuracy: 0.6207 - val_loss: 1.9543 - val_accuracy: 0.5240\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 1.3650 - accuracy: 0.6500 - val_loss: 1.6601 - val_accuracy: 0.5783\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 1.2733 - accuracy: 0.6592 - val_loss: 1.4666 - val_accuracy: 0.6326\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 1.1637 - accuracy: 0.6978 - val_loss: 1.3127 - val_accuracy: 0.6677\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 1.0988 - accuracy: 0.7065 - val_loss: 1.4022 - val_accuracy: 0.6454\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.9743 - accuracy: 0.7414 - val_loss: 1.1884 - val_accuracy: 0.6837\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.8994 - accuracy: 0.7401 - val_loss: 1.1106 - val_accuracy: 0.6997\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.8423 - accuracy: 0.7700 - val_loss: 1.0385 - val_accuracy: 0.7061\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.7764 - accuracy: 0.7834 - val_loss: 1.0650 - val_accuracy: 0.7093\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.7298 - accuracy: 0.7859 - val_loss: 1.0388 - val_accuracy: 0.7220\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.6825 - accuracy: 0.8057 - val_loss: 0.9738 - val_accuracy: 0.7412\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.6237 - accuracy: 0.8299 - val_loss: 0.9837 - val_accuracy: 0.7572\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.6079 - accuracy: 0.8283 - val_loss: 0.8605 - val_accuracy: 0.7444\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.5798 - accuracy: 0.8350 - val_loss: 0.8514 - val_accuracy: 0.7508\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.5676 - accuracy: 0.8354 - val_loss: 0.8599 - val_accuracy: 0.7636\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.5500 - accuracy: 0.8415 - val_loss: 0.8228 - val_accuracy: 0.7700\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.5329 - accuracy: 0.8458 - val_loss: 0.8255 - val_accuracy: 0.7732\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.4898 - accuracy: 0.8700 - val_loss: 0.7658 - val_accuracy: 0.7923\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.4554 - accuracy: 0.8632 - val_loss: 0.8014 - val_accuracy: 0.7668\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.4943 - accuracy: 0.8523 - val_loss: 0.7794 - val_accuracy: 0.7891\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.4388 - accuracy: 0.8760 - val_loss: 0.7431 - val_accuracy: 0.7955\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.4394 - accuracy: 0.8754 - val_loss: 0.7632 - val_accuracy: 0.7796\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.3971 - accuracy: 0.8957 - val_loss: 0.7526 - val_accuracy: 0.7827\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.4238 - accuracy: 0.8705 - val_loss: 0.7913 - val_accuracy: 0.7668\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3999 - accuracy: 0.8777 - val_loss: 0.7204 - val_accuracy: 0.7827\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.3721 - accuracy: 0.8900 - val_loss: 0.7637 - val_accuracy: 0.7891\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.3727 - accuracy: 0.8964 - val_loss: 0.9099 - val_accuracy: 0.7764\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.3743 - accuracy: 0.9016 - val_loss: 0.7481 - val_accuracy: 0.7955\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.3619 - accuracy: 0.9061 - val_loss: 0.7348 - val_accuracy: 0.7732\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.3369 - accuracy: 0.8985 - val_loss: 0.7024 - val_accuracy: 0.7827\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3113 - accuracy: 0.9130 - val_loss: 0.6557 - val_accuracy: 0.8051\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 8s 178ms/step - loss: 0.3153 - accuracy: 0.9157 - val_loss: 0.6585 - val_accuracy: 0.8179\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.2845 - accuracy: 0.9261 - val_loss: 0.6696 - val_accuracy: 0.7987\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2895 - accuracy: 0.9211 - val_loss: 0.6736 - val_accuracy: 0.8019\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2769 - accuracy: 0.9294 - val_loss: 0.6936 - val_accuracy: 0.8115\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2613 - accuracy: 0.9299 - val_loss: 0.6276 - val_accuracy: 0.8115\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2759 - accuracy: 0.9209 - val_loss: 0.6474 - val_accuracy: 0.8147\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2461 - accuracy: 0.9376 - val_loss: 0.6317 - val_accuracy: 0.8147\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2554 - accuracy: 0.9352 - val_loss: 0.6447 - val_accuracy: 0.8179\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2707 - accuracy: 0.9327 - val_loss: 0.6353 - val_accuracy: 0.8211\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2651 - accuracy: 0.9332 - val_loss: 0.6248 - val_accuracy: 0.8275\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.2393 - accuracy: 0.9394 - val_loss: 0.6268 - val_accuracy: 0.8147\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2385 - accuracy: 0.9414 - val_loss: 0.6271 - val_accuracy: 0.8083\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.2335 - accuracy: 0.9408 - val_loss: 0.6224 - val_accuracy: 0.8275\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2396 - accuracy: 0.9377 - val_loss: 0.6381 - val_accuracy: 0.8211\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2497 - accuracy: 0.9350 - val_loss: 0.6262 - val_accuracy: 0.8147\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.2354 - accuracy: 0.9338 - val_loss: 0.6315 - val_accuracy: 0.8083\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2268 - accuracy: 0.9452 - val_loss: 0.6171 - val_accuracy: 0.8211\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2360 - accuracy: 0.9370 - val_loss: 0.6252 - val_accuracy: 0.8307\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2368 - accuracy: 0.9396 - val_loss: 0.6260 - val_accuracy: 0.8275\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2154 - accuracy: 0.9470 - val_loss: 0.6198 - val_accuracy: 0.8307\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2262 - accuracy: 0.9456 - val_loss: 0.6233 - val_accuracy: 0.8147\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2191 - accuracy: 0.9453 - val_loss: 0.6234 - val_accuracy: 0.8243\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2173 - accuracy: 0.9435 - val_loss: 0.6190 - val_accuracy: 0.8243\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.2191 - accuracy: 0.9454 - val_loss: 0.6133 - val_accuracy: 0.8243\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2235 - accuracy: 0.9430 - val_loss: 0.6212 - val_accuracy: 0.8307\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2315 - accuracy: 0.9451 - val_loss: 0.6178 - val_accuracy: 0.8211\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.2310 - accuracy: 0.9398 - val_loss: 0.6127 - val_accuracy: 0.8307\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2162 - accuracy: 0.9457 - val_loss: 0.6184 - val_accuracy: 0.8179\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.2288 - accuracy: 0.9411 - val_loss: 0.6102 - val_accuracy: 0.8211\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2134 - accuracy: 0.9449 - val_loss: 0.6139 - val_accuracy: 0.8275\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2114 - accuracy: 0.9493 - val_loss: 0.6123 - val_accuracy: 0.8307\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2240 - accuracy: 0.9455 - val_loss: 0.6162 - val_accuracy: 0.8243\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2058 - accuracy: 0.9506 - val_loss: 0.6084 - val_accuracy: 0.8307\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2186 - accuracy: 0.9487 - val_loss: 0.6108 - val_accuracy: 0.8275\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2238 - accuracy: 0.9439 - val_loss: 0.6133 - val_accuracy: 0.8243\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2281 - accuracy: 0.9363 - val_loss: 0.6083 - val_accuracy: 0.8211\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2031 - accuracy: 0.9443 - val_loss: 0.6136 - val_accuracy: 0.8211\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2328 - accuracy: 0.9414 - val_loss: 0.6105 - val_accuracy: 0.8275\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2170 - accuracy: 0.9458 - val_loss: 0.6108 - val_accuracy: 0.8179\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2209 - accuracy: 0.9475 - val_loss: 0.6061 - val_accuracy: 0.8307\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2002 - accuracy: 0.9476 - val_loss: 0.6122 - val_accuracy: 0.8339\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2223 - accuracy: 0.9454 - val_loss: 0.6157 - val_accuracy: 0.8275\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2033 - accuracy: 0.9518 - val_loss: 0.6073 - val_accuracy: 0.8307\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2226 - accuracy: 0.9395 - val_loss: 0.6067 - val_accuracy: 0.8275\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2154 - accuracy: 0.9464 - val_loss: 0.6098 - val_accuracy: 0.8275\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2168 - accuracy: 0.9486 - val_loss: 0.6082 - val_accuracy: 0.8243\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2164 - accuracy: 0.9435 - val_loss: 0.6099 - val_accuracy: 0.8275\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2098 - accuracy: 0.9467 - val_loss: 0.6096 - val_accuracy: 0.8243\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.6061 - accuracy: 0.8307\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.6061 - accuracy: 0.8307\n",
      "--------------------Fold_5--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 9s 183ms/step - loss: 3.4280 - accuracy: 0.3378 - val_loss: 3.4393 - val_accuracy: 0.2396\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 2.0556 - accuracy: 0.5336 - val_loss: 1.9430 - val_accuracy: 0.5463\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 1.7248 - accuracy: 0.5903 - val_loss: 2.1378 - val_accuracy: 0.5304\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 1.5707 - accuracy: 0.6246 - val_loss: 1.7869 - val_accuracy: 0.5527\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 1.3816 - accuracy: 0.6496 - val_loss: 1.5200 - val_accuracy: 0.5974\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 1.2676 - accuracy: 0.6763 - val_loss: 1.4007 - val_accuracy: 0.6230\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 1.1305 - accuracy: 0.7121 - val_loss: 1.2460 - val_accuracy: 0.6677\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 1.0768 - accuracy: 0.7092 - val_loss: 1.1612 - val_accuracy: 0.6901\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.9718 - accuracy: 0.7429 - val_loss: 1.0911 - val_accuracy: 0.7125\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.9313 - accuracy: 0.7524 - val_loss: 1.0051 - val_accuracy: 0.7188\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.8545 - accuracy: 0.7763 - val_loss: 0.9631 - val_accuracy: 0.7188\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.8050 - accuracy: 0.7759 - val_loss: 0.8820 - val_accuracy: 0.7540\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.7213 - accuracy: 0.8033 - val_loss: 0.8155 - val_accuracy: 0.7796\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.6971 - accuracy: 0.8063 - val_loss: 0.7620 - val_accuracy: 0.7827\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.6521 - accuracy: 0.8230 - val_loss: 0.7350 - val_accuracy: 0.7955\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.6420 - accuracy: 0.8105 - val_loss: 0.7100 - val_accuracy: 0.8019\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.5669 - accuracy: 0.8405 - val_loss: 0.8417 - val_accuracy: 0.7476\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.5699 - accuracy: 0.8232 - val_loss: 0.7480 - val_accuracy: 0.7955\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.5413 - accuracy: 0.8475 - val_loss: 0.6902 - val_accuracy: 0.8083\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.5385 - accuracy: 0.8374 - val_loss: 0.6434 - val_accuracy: 0.8243\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.4914 - accuracy: 0.8522 - val_loss: 0.6675 - val_accuracy: 0.7891\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.5073 - accuracy: 0.8561 - val_loss: 0.7400 - val_accuracy: 0.8147\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.4607 - accuracy: 0.8662 - val_loss: 0.6328 - val_accuracy: 0.7891\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.4829 - accuracy: 0.8561 - val_loss: 0.5920 - val_accuracy: 0.8147\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.4482 - accuracy: 0.8700 - val_loss: 0.5627 - val_accuracy: 0.8147\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.4531 - accuracy: 0.8638 - val_loss: 0.6285 - val_accuracy: 0.7955\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.4168 - accuracy: 0.8757 - val_loss: 0.6083 - val_accuracy: 0.8179\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3940 - accuracy: 0.8820 - val_loss: 0.6033 - val_accuracy: 0.8019\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3920 - accuracy: 0.8846 - val_loss: 0.5705 - val_accuracy: 0.8243\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3404 - accuracy: 0.9044 - val_loss: 0.5270 - val_accuracy: 0.8307\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.3628 - accuracy: 0.8972 - val_loss: 0.5058 - val_accuracy: 0.8371\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3467 - accuracy: 0.9075 - val_loss: 0.4960 - val_accuracy: 0.8307\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.3262 - accuracy: 0.9062 - val_loss: 0.4962 - val_accuracy: 0.8339\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.3161 - accuracy: 0.9143 - val_loss: 0.5253 - val_accuracy: 0.8403\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.3118 - accuracy: 0.9114 - val_loss: 0.6038 - val_accuracy: 0.8019\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.3333 - accuracy: 0.9054 - val_loss: 0.5104 - val_accuracy: 0.8371\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2973 - accuracy: 0.9256 - val_loss: 0.4898 - val_accuracy: 0.8562\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.3011 - accuracy: 0.9206 - val_loss: 0.4947 - val_accuracy: 0.8307\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2992 - accuracy: 0.9211 - val_loss: 0.4888 - val_accuracy: 0.8435\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2899 - accuracy: 0.9108 - val_loss: 0.4900 - val_accuracy: 0.8435\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2858 - accuracy: 0.9258 - val_loss: 0.4876 - val_accuracy: 0.8498\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2717 - accuracy: 0.9250 - val_loss: 0.4733 - val_accuracy: 0.8530\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2796 - accuracy: 0.9283 - val_loss: 0.4616 - val_accuracy: 0.8594\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2681 - accuracy: 0.9305 - val_loss: 0.4873 - val_accuracy: 0.8562\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2731 - accuracy: 0.9243 - val_loss: 0.4636 - val_accuracy: 0.8530\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2713 - accuracy: 0.9327 - val_loss: 0.4700 - val_accuracy: 0.8498\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2477 - accuracy: 0.9402 - val_loss: 0.4748 - val_accuracy: 0.8498\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2477 - accuracy: 0.9354 - val_loss: 0.4670 - val_accuracy: 0.8562\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2334 - accuracy: 0.9428 - val_loss: 0.4676 - val_accuracy: 0.8466\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2781 - accuracy: 0.9292 - val_loss: 0.4570 - val_accuracy: 0.8562\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2453 - accuracy: 0.9337 - val_loss: 0.4547 - val_accuracy: 0.8626\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2539 - accuracy: 0.9336 - val_loss: 0.4651 - val_accuracy: 0.8658\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2593 - accuracy: 0.9353 - val_loss: 0.4560 - val_accuracy: 0.8594\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.2570 - accuracy: 0.9352 - val_loss: 0.4533 - val_accuracy: 0.8562\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2415 - accuracy: 0.9386 - val_loss: 0.4520 - val_accuracy: 0.8658\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2402 - accuracy: 0.9394 - val_loss: 0.4577 - val_accuracy: 0.8530\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2352 - accuracy: 0.9421 - val_loss: 0.4534 - val_accuracy: 0.8594\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2499 - accuracy: 0.9358 - val_loss: 0.4576 - val_accuracy: 0.8466\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2252 - accuracy: 0.9357 - val_loss: 0.4620 - val_accuracy: 0.8498\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2213 - accuracy: 0.9466 - val_loss: 0.4471 - val_accuracy: 0.8626\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2400 - accuracy: 0.9386 - val_loss: 0.4486 - val_accuracy: 0.8594\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2285 - accuracy: 0.9388 - val_loss: 0.4515 - val_accuracy: 0.8658\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2235 - accuracy: 0.9379 - val_loss: 0.4599 - val_accuracy: 0.8562\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2249 - accuracy: 0.9486 - val_loss: 0.4561 - val_accuracy: 0.8594\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.2265 - accuracy: 0.9397 - val_loss: 0.4542 - val_accuracy: 0.8562\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.2171 - accuracy: 0.9501 - val_loss: 0.4543 - val_accuracy: 0.8594\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.2191 - accuracy: 0.9505 - val_loss: 0.4509 - val_accuracy: 0.8626\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2356 - accuracy: 0.9348 - val_loss: 0.4472 - val_accuracy: 0.8626\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4471 - accuracy: 0.8626\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4471 - accuracy: 0.8626\n",
      "--------------------Fold_6--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 9s 184ms/step - loss: 3.4189 - accuracy: 0.3562 - val_loss: 3.3166 - val_accuracy: 0.2949\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 1.9764 - accuracy: 0.5473 - val_loss: 1.9983 - val_accuracy: 0.5417\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 1.7944 - accuracy: 0.5669 - val_loss: 2.0605 - val_accuracy: 0.5385\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 1.5198 - accuracy: 0.6231 - val_loss: 2.0388 - val_accuracy: 0.5481\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 1.4263 - accuracy: 0.6382 - val_loss: 1.7125 - val_accuracy: 0.5833\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 8s 185ms/step - loss: 1.2330 - accuracy: 0.6804 - val_loss: 1.6308 - val_accuracy: 0.5929\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 1.1801 - accuracy: 0.6826 - val_loss: 1.4636 - val_accuracy: 0.6186\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 1.0298 - accuracy: 0.7256 - val_loss: 1.2574 - val_accuracy: 0.6699\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.9718 - accuracy: 0.7392 - val_loss: 1.1678 - val_accuracy: 0.6987\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.9239 - accuracy: 0.7509 - val_loss: 1.1308 - val_accuracy: 0.7115\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.8644 - accuracy: 0.7627 - val_loss: 1.0906 - val_accuracy: 0.7308\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.7988 - accuracy: 0.7784 - val_loss: 0.9962 - val_accuracy: 0.7244\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.7607 - accuracy: 0.7848 - val_loss: 0.9616 - val_accuracy: 0.7372\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.6818 - accuracy: 0.8068 - val_loss: 0.9201 - val_accuracy: 0.7500\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.6851 - accuracy: 0.7813 - val_loss: 0.8458 - val_accuracy: 0.7853\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.6436 - accuracy: 0.8106 - val_loss: 0.8556 - val_accuracy: 0.7756\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.5787 - accuracy: 0.8317 - val_loss: 0.8241 - val_accuracy: 0.7628\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.5265 - accuracy: 0.8527 - val_loss: 0.7859 - val_accuracy: 0.7853\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.5466 - accuracy: 0.8440 - val_loss: 0.8072 - val_accuracy: 0.7660\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.5264 - accuracy: 0.8389 - val_loss: 0.7157 - val_accuracy: 0.8077\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.5301 - accuracy: 0.8423 - val_loss: 0.8158 - val_accuracy: 0.7692\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.5019 - accuracy: 0.8451 - val_loss: 0.6916 - val_accuracy: 0.8237\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.4580 - accuracy: 0.8587 - val_loss: 0.7483 - val_accuracy: 0.7853\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.4441 - accuracy: 0.8612 - val_loss: 0.6744 - val_accuracy: 0.8269\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.4171 - accuracy: 0.8763 - val_loss: 0.7086 - val_accuracy: 0.8045\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.4237 - accuracy: 0.8671 - val_loss: 0.6816 - val_accuracy: 0.8141\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.4196 - accuracy: 0.8794 - val_loss: 0.7092 - val_accuracy: 0.8045\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.4300 - accuracy: 0.8671 - val_loss: 0.6759 - val_accuracy: 0.8173\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.3999 - accuracy: 0.8836 - val_loss: 0.6336 - val_accuracy: 0.8301\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.3460 - accuracy: 0.9085 - val_loss: 0.6318 - val_accuracy: 0.8269\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3504 - accuracy: 0.9026 - val_loss: 0.6294 - val_accuracy: 0.8333\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.3414 - accuracy: 0.9031 - val_loss: 0.6806 - val_accuracy: 0.8077\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3350 - accuracy: 0.8995 - val_loss: 0.6112 - val_accuracy: 0.8365\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3135 - accuracy: 0.9111 - val_loss: 0.6319 - val_accuracy: 0.8237\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.3016 - accuracy: 0.9188 - val_loss: 0.6328 - val_accuracy: 0.8237\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.3172 - accuracy: 0.9150 - val_loss: 0.6856 - val_accuracy: 0.8141\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.3330 - accuracy: 0.9093 - val_loss: 0.6125 - val_accuracy: 0.8397\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3031 - accuracy: 0.9178 - val_loss: 0.6112 - val_accuracy: 0.8333\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 8s 185ms/step - loss: 0.2892 - accuracy: 0.9186 - val_loss: 0.6185 - val_accuracy: 0.8365\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2721 - accuracy: 0.9292 - val_loss: 0.6117 - val_accuracy: 0.8429\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2786 - accuracy: 0.9253 - val_loss: 0.6412 - val_accuracy: 0.8365\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.6112 - accuracy: 0.8365\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.6112 - accuracy: 0.8365\n",
      "--------------------Fold_7--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 9s 184ms/step - loss: 3.4262 - accuracy: 0.3292 - val_loss: 3.4112 - val_accuracy: 0.2212\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 1.9775 - accuracy: 0.5514 - val_loss: 1.8765 - val_accuracy: 0.5385\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 1.7195 - accuracy: 0.5812 - val_loss: 1.9843 - val_accuracy: 0.5449\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 1.5073 - accuracy: 0.6315 - val_loss: 1.7828 - val_accuracy: 0.5513\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 1.3913 - accuracy: 0.6516 - val_loss: 1.6510 - val_accuracy: 0.5737\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 1.2870 - accuracy: 0.6613 - val_loss: 1.3778 - val_accuracy: 0.6314\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 1.1337 - accuracy: 0.6999 - val_loss: 1.3402 - val_accuracy: 0.6378\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 1.0869 - accuracy: 0.7074 - val_loss: 1.2187 - val_accuracy: 0.6635\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 1.0000 - accuracy: 0.7427 - val_loss: 1.0770 - val_accuracy: 0.6987\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.9167 - accuracy: 0.7501 - val_loss: 1.0119 - val_accuracy: 0.7340\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.8363 - accuracy: 0.7754 - val_loss: 0.9565 - val_accuracy: 0.7147\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.7700 - accuracy: 0.7837 - val_loss: 0.9048 - val_accuracy: 0.7692\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.7410 - accuracy: 0.7914 - val_loss: 0.8613 - val_accuracy: 0.7340\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.7019 - accuracy: 0.8061 - val_loss: 0.8285 - val_accuracy: 0.7468\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.6931 - accuracy: 0.8077 - val_loss: 0.7562 - val_accuracy: 0.7821\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.6254 - accuracy: 0.8129 - val_loss: 0.7584 - val_accuracy: 0.7917\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.5935 - accuracy: 0.8303 - val_loss: 0.7200 - val_accuracy: 0.8173\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.6075 - accuracy: 0.8197 - val_loss: 0.7311 - val_accuracy: 0.8045\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.5245 - accuracy: 0.8542 - val_loss: 0.7543 - val_accuracy: 0.7788\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.5277 - accuracy: 0.8502 - val_loss: 0.6576 - val_accuracy: 0.8173\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.5120 - accuracy: 0.8572 - val_loss: 0.6416 - val_accuracy: 0.8109\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.4948 - accuracy: 0.8537 - val_loss: 0.7707 - val_accuracy: 0.7788\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.4808 - accuracy: 0.8615 - val_loss: 0.6281 - val_accuracy: 0.8077\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.4742 - accuracy: 0.8575 - val_loss: 0.6607 - val_accuracy: 0.7917\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.4749 - accuracy: 0.8687 - val_loss: 0.6100 - val_accuracy: 0.8205\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.3953 - accuracy: 0.8872 - val_loss: 0.5698 - val_accuracy: 0.8462\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.4083 - accuracy: 0.8765 - val_loss: 0.5728 - val_accuracy: 0.8462\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.3918 - accuracy: 0.8911 - val_loss: 0.5473 - val_accuracy: 0.7981\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.3982 - accuracy: 0.8895 - val_loss: 0.5657 - val_accuracy: 0.8462\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.3758 - accuracy: 0.8927 - val_loss: 0.5812 - val_accuracy: 0.8205\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.3630 - accuracy: 0.8957 - val_loss: 0.5508 - val_accuracy: 0.8365\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.3525 - accuracy: 0.8940 - val_loss: 0.5964 - val_accuracy: 0.8269\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.3128 - accuracy: 0.9161 - val_loss: 0.5147 - val_accuracy: 0.8429\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.3194 - accuracy: 0.9098 - val_loss: 0.5536 - val_accuracy: 0.8397\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.3289 - accuracy: 0.9068 - val_loss: 0.5416 - val_accuracy: 0.8462\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.2872 - accuracy: 0.9259 - val_loss: 0.5391 - val_accuracy: 0.8301\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.3088 - accuracy: 0.9147 - val_loss: 0.4995 - val_accuracy: 0.8429\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 8s 186ms/step - loss: 0.3201 - accuracy: 0.9092 - val_loss: 0.5396 - val_accuracy: 0.8237\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2767 - accuracy: 0.9239 - val_loss: 0.5355 - val_accuracy: 0.8333\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2785 - accuracy: 0.9284 - val_loss: 0.5197 - val_accuracy: 0.8494\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2925 - accuracy: 0.9130 - val_loss: 0.5237 - val_accuracy: 0.8365\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2505 - accuracy: 0.9395 - val_loss: 0.4959 - val_accuracy: 0.8429\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2538 - accuracy: 0.9378 - val_loss: 0.4973 - val_accuracy: 0.8365\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2596 - accuracy: 0.9331 - val_loss: 0.4880 - val_accuracy: 0.8429\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2475 - accuracy: 0.9342 - val_loss: 0.4879 - val_accuracy: 0.8494\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2612 - accuracy: 0.9288 - val_loss: 0.4812 - val_accuracy: 0.8526\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2393 - accuracy: 0.9385 - val_loss: 0.4787 - val_accuracy: 0.8462\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.2448 - accuracy: 0.9360 - val_loss: 0.4892 - val_accuracy: 0.8429\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2370 - accuracy: 0.9350 - val_loss: 0.5135 - val_accuracy: 0.8462\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2252 - accuracy: 0.9432 - val_loss: 0.4839 - val_accuracy: 0.8526\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.2253 - accuracy: 0.9413 - val_loss: 0.4822 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2311 - accuracy: 0.9449 - val_loss: 0.4811 - val_accuracy: 0.8558\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2349 - accuracy: 0.9405 - val_loss: 0.4690 - val_accuracy: 0.8462\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2339 - accuracy: 0.9376 - val_loss: 0.4783 - val_accuracy: 0.8526\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2261 - accuracy: 0.9417 - val_loss: 0.4750 - val_accuracy: 0.8526\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2195 - accuracy: 0.9426 - val_loss: 0.4674 - val_accuracy: 0.8558\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2395 - accuracy: 0.9381 - val_loss: 0.4670 - val_accuracy: 0.8526\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2313 - accuracy: 0.9382 - val_loss: 0.4553 - val_accuracy: 0.8558\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2323 - accuracy: 0.9427 - val_loss: 0.4645 - val_accuracy: 0.8558\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2289 - accuracy: 0.9459 - val_loss: 0.4574 - val_accuracy: 0.8558\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2067 - accuracy: 0.9497 - val_loss: 0.4662 - val_accuracy: 0.8462\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2172 - accuracy: 0.9468 - val_loss: 0.4708 - val_accuracy: 0.8526\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2126 - accuracy: 0.9443 - val_loss: 0.4670 - val_accuracy: 0.8526\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2220 - accuracy: 0.9397 - val_loss: 0.4585 - val_accuracy: 0.8558\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.1986 - accuracy: 0.9542 - val_loss: 0.4633 - val_accuracy: 0.8526\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2105 - accuracy: 0.9483 - val_loss: 0.4608 - val_accuracy: 0.8526\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4553 - accuracy: 0.8558\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4553 - accuracy: 0.8558\n",
      "--------------------Fold_8--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 9s 186ms/step - loss: 3.3943 - accuracy: 0.3472 - val_loss: 3.2599 - val_accuracy: 0.3173\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 2.0112 - accuracy: 0.5408 - val_loss: 1.8584 - val_accuracy: 0.5385\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 1.7211 - accuracy: 0.5914 - val_loss: 1.8750 - val_accuracy: 0.5641\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 1.5069 - accuracy: 0.6342 - val_loss: 1.8492 - val_accuracy: 0.5705\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 8s 185ms/step - loss: 1.4494 - accuracy: 0.6297 - val_loss: 1.5701 - val_accuracy: 0.6058\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 1.2839 - accuracy: 0.6591 - val_loss: 1.4310 - val_accuracy: 0.6378\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 1.1322 - accuracy: 0.7070 - val_loss: 1.2462 - val_accuracy: 0.6410\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 1.0399 - accuracy: 0.7190 - val_loss: 1.2043 - val_accuracy: 0.6635\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.9885 - accuracy: 0.7357 - val_loss: 1.0543 - val_accuracy: 0.7019\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.8679 - accuracy: 0.7674 - val_loss: 1.0066 - val_accuracy: 0.7147\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.8301 - accuracy: 0.7681 - val_loss: 0.9485 - val_accuracy: 0.7179\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.7946 - accuracy: 0.7870 - val_loss: 0.9041 - val_accuracy: 0.7276\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.7052 - accuracy: 0.8114 - val_loss: 0.8144 - val_accuracy: 0.7340\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.7033 - accuracy: 0.8061 - val_loss: 0.9005 - val_accuracy: 0.7724\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.6795 - accuracy: 0.8035 - val_loss: 0.7892 - val_accuracy: 0.7500\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.6201 - accuracy: 0.8251 - val_loss: 0.8321 - val_accuracy: 0.7756\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.6084 - accuracy: 0.8241 - val_loss: 0.7088 - val_accuracy: 0.7756\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.5697 - accuracy: 0.8356 - val_loss: 0.6970 - val_accuracy: 0.8109\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.5500 - accuracy: 0.8325 - val_loss: 0.6611 - val_accuracy: 0.7821\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.5438 - accuracy: 0.8333 - val_loss: 0.6099 - val_accuracy: 0.8205\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.4886 - accuracy: 0.8582 - val_loss: 0.6175 - val_accuracy: 0.7853\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.4849 - accuracy: 0.8632 - val_loss: 0.6175 - val_accuracy: 0.7724\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.4607 - accuracy: 0.8641 - val_loss: 0.6343 - val_accuracy: 0.7692\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.4709 - accuracy: 0.8681 - val_loss: 0.5986 - val_accuracy: 0.8141\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.4200 - accuracy: 0.8791 - val_loss: 0.6160 - val_accuracy: 0.7821\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.4259 - accuracy: 0.8794 - val_loss: 0.5795 - val_accuracy: 0.8141\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.4105 - accuracy: 0.8842 - val_loss: 0.5776 - val_accuracy: 0.8141\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.3961 - accuracy: 0.8860 - val_loss: 0.5648 - val_accuracy: 0.8141\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3605 - accuracy: 0.8946 - val_loss: 0.6027 - val_accuracy: 0.7917\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.3808 - accuracy: 0.8911 - val_loss: 0.5889 - val_accuracy: 0.8173\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3552 - accuracy: 0.8938 - val_loss: 0.6089 - val_accuracy: 0.8109\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3884 - accuracy: 0.8858 - val_loss: 0.5764 - val_accuracy: 0.8109\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.3218 - accuracy: 0.9101 - val_loss: 0.5410 - val_accuracy: 0.8397\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.3190 - accuracy: 0.9071 - val_loss: 0.5031 - val_accuracy: 0.8365\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2981 - accuracy: 0.9222 - val_loss: 0.5216 - val_accuracy: 0.8237\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2877 - accuracy: 0.9295 - val_loss: 0.5116 - val_accuracy: 0.8301\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3139 - accuracy: 0.9097 - val_loss: 0.5179 - val_accuracy: 0.8333\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2916 - accuracy: 0.9188 - val_loss: 0.5442 - val_accuracy: 0.7885\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2848 - accuracy: 0.9253 - val_loss: 0.4576 - val_accuracy: 0.8462\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2748 - accuracy: 0.9311 - val_loss: 0.4609 - val_accuracy: 0.8622\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2582 - accuracy: 0.9377 - val_loss: 0.4569 - val_accuracy: 0.8622\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.2552 - accuracy: 0.9343 - val_loss: 0.4536 - val_accuracy: 0.8558\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2667 - accuracy: 0.9298 - val_loss: 0.4430 - val_accuracy: 0.8654\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2567 - accuracy: 0.9390 - val_loss: 0.4443 - val_accuracy: 0.8686\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2722 - accuracy: 0.9261 - val_loss: 0.4680 - val_accuracy: 0.8365\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2528 - accuracy: 0.9339 - val_loss: 0.4655 - val_accuracy: 0.8494\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2478 - accuracy: 0.9357 - val_loss: 0.4621 - val_accuracy: 0.8654\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 8s 185ms/step - loss: 0.2489 - accuracy: 0.9380 - val_loss: 0.4472 - val_accuracy: 0.8622\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2338 - accuracy: 0.9420 - val_loss: 0.4437 - val_accuracy: 0.8590\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2332 - accuracy: 0.9439 - val_loss: 0.4420 - val_accuracy: 0.8590\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2271 - accuracy: 0.9403 - val_loss: 0.4526 - val_accuracy: 0.8526\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2351 - accuracy: 0.9389 - val_loss: 0.4422 - val_accuracy: 0.8622\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.2529 - accuracy: 0.9370 - val_loss: 0.4367 - val_accuracy: 0.8590\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2298 - accuracy: 0.9455 - val_loss: 0.4372 - val_accuracy: 0.8686\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2424 - accuracy: 0.9341 - val_loss: 0.4410 - val_accuracy: 0.8590\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2616 - accuracy: 0.9294 - val_loss: 0.4409 - val_accuracy: 0.8654\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 8s 187ms/step - loss: 0.2505 - accuracy: 0.9361 - val_loss: 0.4443 - val_accuracy: 0.8654\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2275 - accuracy: 0.9437 - val_loss: 0.4351 - val_accuracy: 0.8590\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2314 - accuracy: 0.9433 - val_loss: 0.4328 - val_accuracy: 0.8622\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2202 - accuracy: 0.9417 - val_loss: 0.4337 - val_accuracy: 0.8654\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2107 - accuracy: 0.9510 - val_loss: 0.4313 - val_accuracy: 0.8686\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2332 - accuracy: 0.9404 - val_loss: 0.4305 - val_accuracy: 0.8654\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2392 - accuracy: 0.9386 - val_loss: 0.4321 - val_accuracy: 0.8654\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2281 - accuracy: 0.9371 - val_loss: 0.4342 - val_accuracy: 0.8622\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2237 - accuracy: 0.9469 - val_loss: 0.4351 - val_accuracy: 0.8718\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2331 - accuracy: 0.9410 - val_loss: 0.4341 - val_accuracy: 0.8654\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2341 - accuracy: 0.9390 - val_loss: 0.4307 - val_accuracy: 0.8686\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2294 - accuracy: 0.9373 - val_loss: 0.4312 - val_accuracy: 0.8654\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2112 - accuracy: 0.9465 - val_loss: 0.4315 - val_accuracy: 0.8686\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2300 - accuracy: 0.9372 - val_loss: 0.4303 - val_accuracy: 0.8622\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.2243 - accuracy: 0.9438 - val_loss: 0.4296 - val_accuracy: 0.8622\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2239 - accuracy: 0.9414 - val_loss: 0.4273 - val_accuracy: 0.8686\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2191 - accuracy: 0.9496 - val_loss: 0.4265 - val_accuracy: 0.8686\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2216 - accuracy: 0.9453 - val_loss: 0.4267 - val_accuracy: 0.8654\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2275 - accuracy: 0.9426 - val_loss: 0.4265 - val_accuracy: 0.8654\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2251 - accuracy: 0.9385 - val_loss: 0.4258 - val_accuracy: 0.8654\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2181 - accuracy: 0.9390 - val_loss: 0.4288 - val_accuracy: 0.8718\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2086 - accuracy: 0.9552 - val_loss: 0.4277 - val_accuracy: 0.8718\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2182 - accuracy: 0.9463 - val_loss: 0.4275 - val_accuracy: 0.8750\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2229 - accuracy: 0.9448 - val_loss: 0.4274 - val_accuracy: 0.8654\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2254 - accuracy: 0.9460 - val_loss: 0.4263 - val_accuracy: 0.8654\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2038 - accuracy: 0.9525 - val_loss: 0.4267 - val_accuracy: 0.8654\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2245 - accuracy: 0.9492 - val_loss: 0.4257 - val_accuracy: 0.8654\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2237 - accuracy: 0.9395 - val_loss: 0.4252 - val_accuracy: 0.8654\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2255 - accuracy: 0.9416 - val_loss: 0.4258 - val_accuracy: 0.8686\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2193 - accuracy: 0.9455 - val_loss: 0.4253 - val_accuracy: 0.8654\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2099 - accuracy: 0.9437 - val_loss: 0.4252 - val_accuracy: 0.8686\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2128 - accuracy: 0.9445 - val_loss: 0.4249 - val_accuracy: 0.8654\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2186 - accuracy: 0.9460 - val_loss: 0.4249 - val_accuracy: 0.8686\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2171 - accuracy: 0.9462 - val_loss: 0.4251 - val_accuracy: 0.8654\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2070 - accuracy: 0.9479 - val_loss: 0.4255 - val_accuracy: 0.8686\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2135 - accuracy: 0.9421 - val_loss: 0.4253 - val_accuracy: 0.8686\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.2158 - accuracy: 0.9466 - val_loss: 0.4253 - val_accuracy: 0.8654\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2068 - accuracy: 0.9497 - val_loss: 0.4258 - val_accuracy: 0.8654\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2133 - accuracy: 0.9448 - val_loss: 0.4252 - val_accuracy: 0.8654\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2051 - accuracy: 0.9466 - val_loss: 0.4256 - val_accuracy: 0.8654\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4249 - accuracy: 0.8654\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4249 - accuracy: 0.8654\n",
      "--------------------Fold_9--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 9s 183ms/step - loss: 3.3783 - accuracy: 0.3489 - val_loss: 2.9276 - val_accuracy: 0.4551\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 1.9826 - accuracy: 0.5604 - val_loss: 1.9077 - val_accuracy: 0.5449\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 1.7716 - accuracy: 0.5709 - val_loss: 1.8158 - val_accuracy: 0.5609\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 1.5370 - accuracy: 0.6251 - val_loss: 1.6927 - val_accuracy: 0.5609\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 1.3952 - accuracy: 0.6416 - val_loss: 1.5730 - val_accuracy: 0.5833\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 1.2643 - accuracy: 0.6657 - val_loss: 1.3282 - val_accuracy: 0.6218\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 1.1647 - accuracy: 0.6902 - val_loss: 1.2566 - val_accuracy: 0.6538\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 1.0608 - accuracy: 0.7219 - val_loss: 1.1629 - val_accuracy: 0.6667\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 1.0091 - accuracy: 0.7301 - val_loss: 1.0633 - val_accuracy: 0.7179\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.9020 - accuracy: 0.7562 - val_loss: 1.0346 - val_accuracy: 0.7115\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.8648 - accuracy: 0.7585 - val_loss: 1.0035 - val_accuracy: 0.6987\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.7519 - accuracy: 0.7962 - val_loss: 0.8986 - val_accuracy: 0.7468\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.7723 - accuracy: 0.7746 - val_loss: 0.8348 - val_accuracy: 0.7468\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.6736 - accuracy: 0.8136 - val_loss: 0.8409 - val_accuracy: 0.7692\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.6625 - accuracy: 0.8096 - val_loss: 0.7517 - val_accuracy: 0.7917\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.6032 - accuracy: 0.8225 - val_loss: 0.7323 - val_accuracy: 0.7821\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.6164 - accuracy: 0.8127 - val_loss: 0.7655 - val_accuracy: 0.7308\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.5579 - accuracy: 0.8352 - val_loss: 0.6725 - val_accuracy: 0.7885\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.5341 - accuracy: 0.8449 - val_loss: 0.6899 - val_accuracy: 0.7917\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.5310 - accuracy: 0.8426 - val_loss: 0.6850 - val_accuracy: 0.7756\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.4796 - accuracy: 0.8560 - val_loss: 0.6845 - val_accuracy: 0.8141\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.4967 - accuracy: 0.8466 - val_loss: 0.6169 - val_accuracy: 0.8109\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.4601 - accuracy: 0.8738 - val_loss: 0.5979 - val_accuracy: 0.8141\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.4355 - accuracy: 0.8695 - val_loss: 0.5814 - val_accuracy: 0.8141\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.4511 - accuracy: 0.8638 - val_loss: 0.5766 - val_accuracy: 0.8205\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.3942 - accuracy: 0.8931 - val_loss: 0.5817 - val_accuracy: 0.8173\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.4032 - accuracy: 0.8814 - val_loss: 0.5770 - val_accuracy: 0.8173\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.4382 - accuracy: 0.8677 - val_loss: 0.7069 - val_accuracy: 0.7660\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.3894 - accuracy: 0.8941 - val_loss: 0.5766 - val_accuracy: 0.8013\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.3686 - accuracy: 0.8951 - val_loss: 0.5157 - val_accuracy: 0.8269\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.3564 - accuracy: 0.8994 - val_loss: 0.5174 - val_accuracy: 0.8365\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3170 - accuracy: 0.9155 - val_loss: 0.5086 - val_accuracy: 0.8365\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.3380 - accuracy: 0.9067 - val_loss: 0.5103 - val_accuracy: 0.8141\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.3070 - accuracy: 0.9140 - val_loss: 0.4884 - val_accuracy: 0.8333\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3238 - accuracy: 0.9026 - val_loss: 0.4924 - val_accuracy: 0.8397\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2925 - accuracy: 0.9193 - val_loss: 0.4856 - val_accuracy: 0.8333\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.3219 - accuracy: 0.9062 - val_loss: 0.4964 - val_accuracy: 0.8237\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3114 - accuracy: 0.9100 - val_loss: 0.4725 - val_accuracy: 0.8269\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2949 - accuracy: 0.9169 - val_loss: 0.4758 - val_accuracy: 0.8397\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3110 - accuracy: 0.9167 - val_loss: 0.5190 - val_accuracy: 0.8333\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2735 - accuracy: 0.9259 - val_loss: 0.4621 - val_accuracy: 0.8365\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.3084 - accuracy: 0.9129 - val_loss: 0.4818 - val_accuracy: 0.8301\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3023 - accuracy: 0.9086 - val_loss: 0.4979 - val_accuracy: 0.8237\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2596 - accuracy: 0.9329 - val_loss: 0.5195 - val_accuracy: 0.8205\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2735 - accuracy: 0.9223 - val_loss: 0.4901 - val_accuracy: 0.8301\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2674 - accuracy: 0.9263 - val_loss: 0.4668 - val_accuracy: 0.8365\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 8s 186ms/step - loss: 0.2441 - accuracy: 0.9326 - val_loss: 0.4638 - val_accuracy: 0.8333\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2596 - accuracy: 0.9320 - val_loss: 0.4638 - val_accuracy: 0.8429\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2550 - accuracy: 0.9318 - val_loss: 0.4599 - val_accuracy: 0.8397\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2341 - accuracy: 0.9370 - val_loss: 0.4552 - val_accuracy: 0.8462\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2228 - accuracy: 0.9429 - val_loss: 0.4725 - val_accuracy: 0.8429\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2580 - accuracy: 0.9299 - val_loss: 0.4369 - val_accuracy: 0.8526\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2516 - accuracy: 0.9324 - val_loss: 0.4869 - val_accuracy: 0.8462\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2343 - accuracy: 0.9314 - val_loss: 0.4540 - val_accuracy: 0.8365\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2158 - accuracy: 0.9470 - val_loss: 0.4458 - val_accuracy: 0.8365\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2193 - accuracy: 0.9392 - val_loss: 0.4775 - val_accuracy: 0.8301\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2138 - accuracy: 0.9422 - val_loss: 0.4411 - val_accuracy: 0.8365\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.2219 - accuracy: 0.9468 - val_loss: 0.4440 - val_accuracy: 0.8494\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2081 - accuracy: 0.9475 - val_loss: 0.4471 - val_accuracy: 0.8494\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 0.2171 - accuracy: 0.9430 - val_loss: 0.4472 - val_accuracy: 0.8462\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4369 - accuracy: 0.8526\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4369 - accuracy: 0.8526\n",
      "--------------------Fold_10--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 9s 183ms/step - loss: 3.4090 - accuracy: 0.3351 - val_loss: 2.9942 - val_accuracy: 0.3814\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 1.9950 - accuracy: 0.5441 - val_loss: 1.8966 - val_accuracy: 0.5449\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 1.6929 - accuracy: 0.5890 - val_loss: 1.8593 - val_accuracy: 0.5417\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 1.5276 - accuracy: 0.6258 - val_loss: 1.6897 - val_accuracy: 0.5769\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 1.3816 - accuracy: 0.6517 - val_loss: 1.5503 - val_accuracy: 0.6026\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 1.3005 - accuracy: 0.6587 - val_loss: 1.3712 - val_accuracy: 0.6410\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 1.1707 - accuracy: 0.6903 - val_loss: 1.2846 - val_accuracy: 0.6538\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 1.0711 - accuracy: 0.7139 - val_loss: 1.1105 - val_accuracy: 0.7115\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 8s 184ms/step - loss: 1.0148 - accuracy: 0.7113 - val_loss: 1.0171 - val_accuracy: 0.7115\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.8945 - accuracy: 0.7654 - val_loss: 0.9971 - val_accuracy: 0.7404\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.8492 - accuracy: 0.7610 - val_loss: 0.8766 - val_accuracy: 0.7500\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.7745 - accuracy: 0.7834 - val_loss: 0.8687 - val_accuracy: 0.7596\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.7804 - accuracy: 0.7886 - val_loss: 0.8666 - val_accuracy: 0.7692\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.7094 - accuracy: 0.8049 - val_loss: 0.8277 - val_accuracy: 0.7724\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.6759 - accuracy: 0.8145 - val_loss: 0.7555 - val_accuracy: 0.8141\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.6615 - accuracy: 0.8233 - val_loss: 0.7008 - val_accuracy: 0.8077\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.6073 - accuracy: 0.8199 - val_loss: 0.6731 - val_accuracy: 0.8109\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.5522 - accuracy: 0.8348 - val_loss: 0.6461 - val_accuracy: 0.8269\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 8s 185ms/step - loss: 0.5383 - accuracy: 0.8463 - val_loss: 0.6329 - val_accuracy: 0.8205\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.5298 - accuracy: 0.8544 - val_loss: 0.6212 - val_accuracy: 0.8365\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.5350 - accuracy: 0.8486 - val_loss: 0.7384 - val_accuracy: 0.7885\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.5122 - accuracy: 0.8514 - val_loss: 0.5705 - val_accuracy: 0.8397\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.5070 - accuracy: 0.8528 - val_loss: 0.6085 - val_accuracy: 0.8141\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.4421 - accuracy: 0.8736 - val_loss: 0.7051 - val_accuracy: 0.7949\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.4600 - accuracy: 0.8655 - val_loss: 0.5246 - val_accuracy: 0.8109\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.4115 - accuracy: 0.8775 - val_loss: 0.6344 - val_accuracy: 0.8237\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.4435 - accuracy: 0.8647 - val_loss: 0.5483 - val_accuracy: 0.8301\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.4168 - accuracy: 0.8750 - val_loss: 0.5620 - val_accuracy: 0.8301\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3954 - accuracy: 0.8829 - val_loss: 0.5526 - val_accuracy: 0.8269\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.3629 - accuracy: 0.8944 - val_loss: 0.5091 - val_accuracy: 0.8269\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.3395 - accuracy: 0.9105 - val_loss: 0.4939 - val_accuracy: 0.8429\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.3169 - accuracy: 0.9181 - val_loss: 0.5328 - val_accuracy: 0.8173\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3267 - accuracy: 0.9030 - val_loss: 0.4844 - val_accuracy: 0.8397\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3425 - accuracy: 0.9026 - val_loss: 0.5376 - val_accuracy: 0.8173\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.3120 - accuracy: 0.9223 - val_loss: 0.5188 - val_accuracy: 0.8397\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.3025 - accuracy: 0.9229 - val_loss: 0.4938 - val_accuracy: 0.8397\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.3213 - accuracy: 0.9137 - val_loss: 0.5077 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.3000 - accuracy: 0.9233 - val_loss: 0.4701 - val_accuracy: 0.8526\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2890 - accuracy: 0.9261 - val_loss: 0.4789 - val_accuracy: 0.8397\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.3104 - accuracy: 0.9193 - val_loss: 0.4497 - val_accuracy: 0.8494\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2679 - accuracy: 0.9350 - val_loss: 0.4620 - val_accuracy: 0.8429\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2819 - accuracy: 0.9242 - val_loss: 0.4759 - val_accuracy: 0.8462\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2805 - accuracy: 0.9279 - val_loss: 0.4662 - val_accuracy: 0.8494\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2949 - accuracy: 0.9222 - val_loss: 0.4649 - val_accuracy: 0.8462\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2654 - accuracy: 0.9329 - val_loss: 0.4510 - val_accuracy: 0.8622\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2643 - accuracy: 0.9278 - val_loss: 0.4519 - val_accuracy: 0.8462\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2649 - accuracy: 0.9356 - val_loss: 0.4391 - val_accuracy: 0.8494\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2608 - accuracy: 0.9330 - val_loss: 0.4540 - val_accuracy: 0.8558\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2513 - accuracy: 0.9336 - val_loss: 0.4467 - val_accuracy: 0.8494\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2458 - accuracy: 0.9420 - val_loss: 0.4498 - val_accuracy: 0.8590\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 8s 183ms/step - loss: 0.2591 - accuracy: 0.9363 - val_loss: 0.4657 - val_accuracy: 0.8558\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 8s 180ms/step - loss: 0.2616 - accuracy: 0.9389 - val_loss: 0.4503 - val_accuracy: 0.8558\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2436 - accuracy: 0.9355 - val_loss: 0.4509 - val_accuracy: 0.8526\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.2527 - accuracy: 0.9341 - val_loss: 0.4429 - val_accuracy: 0.8558\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 8s 182ms/step - loss: 0.2531 - accuracy: 0.9397 - val_loss: 0.4490 - val_accuracy: 0.8494\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4391 - accuracy: 0.8494\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4391 - accuracy: 0.8494\n",
      "\n",
      "K-fold cross validation Auc: ['0.8562', '0.8466', '0.8722', '0.8307', '0.8626', '0.8365', '0.8558', '0.8654', '0.8526', '0.8494']\n",
      "\n",
      "K-fold cross validation loss: ['0.5350', '0.4758', '0.4192', '0.6061', '0.4471', '0.6112', '0.4553', '0.4249', '0.4369', '0.4391']\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits = 10, random_state = 2021, shuffle = True)\n",
    "reLR = ReduceLROnPlateau(patience = 4,verbose = 1,factor = 0.5) \n",
    "es =EarlyStopping(monitor='val_loss', patience=8, mode='min')\n",
    "\n",
    "accuracy = []\n",
    "losss=[]\n",
    "models=[]\n",
    "\n",
    "for i, (train, validation) in enumerate(skf.split(X, y.argmax(1))) :\n",
    "    mc = ModelCheckpoint(f'./model_kf/cv_study{i + 1}.h5',save_best_only=True, verbose=0, monitor = 'val_loss', mode = 'min', save_weights_only=True)\n",
    "    print(\"-\" * 20 +\"Fold_\"+str(i+1)+ \"-\" * 20)\n",
    "    model = cnn_model((600,18),61)\n",
    "    history = model.fit(X[train], y[train], epochs = 100, validation_data= (X[validation], y[validation]), \n",
    "                        verbose=1,batch_size=64,callbacks=[es,mc,reLR])\n",
    "    model.load_weights(f'./model_kf/cv_study{i + 1}.h5')\n",
    "    \n",
    "    k_accuracy = '%.4f' % (model.evaluate(X[validation], y[validation])[1])\n",
    "    k_loss = '%.4f' % (model.evaluate(X[validation], y[validation])[0])\n",
    "    \n",
    "    accuracy.append(k_accuracy)\n",
    "    losss.append(k_loss)\n",
    "    models.append(model)\n",
    "\n",
    "print('\\nK-fold cross validation Auc: {}'.format(accuracy))\n",
    "print('\\nK-fold cross validation loss: {}'.format(losss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(782, 600, 18)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X=np.array(test_sc.iloc[:,2:]).reshape(782, 600, -1)\n",
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.11362115e-05, 2.25996450e-06, 2.11680984e-07, ...,\n",
       "        6.39248919e-03, 1.50766409e-05, 3.40101496e-06],\n",
       "       [4.13231173e-04, 1.99007154e-05, 1.22563812e-04, ...,\n",
       "        8.93750075e-06, 2.06302539e-05, 1.22722922e-05],\n",
       "       [1.86802447e-03, 3.26019563e-02, 1.62000761e-05, ...,\n",
       "        8.92708835e-04, 1.20446784e-02, 2.22884724e-03],\n",
       "       ...,\n",
       "       [4.16979339e-04, 3.25313522e-06, 1.09946477e-05, ...,\n",
       "        1.80470997e-05, 1.36069389e-06, 7.54901499e-04],\n",
       "       [3.85870408e-06, 8.71700991e-04, 9.34987668e-07, ...,\n",
       "        1.06083007e-07, 1.25161705e-05, 4.91666885e-09],\n",
       "       [9.32284092e-05, 4.08958658e-06, 1.09709674e-06, ...,\n",
       "        9.87853055e-05, 9.04675460e-07, 1.53993984e-04]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = []\n",
    "for model in models:\n",
    "    pred = model.predict(test_X)\n",
    "    preds.append(pred)\n",
    "pred = np.mean(preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>...</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3125</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.116810e-07</td>\n",
       "      <td>4.708937e-08</td>\n",
       "      <td>1.865657e-04</td>\n",
       "      <td>1.124369e-07</td>\n",
       "      <td>3.247155e-04</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.424222e-07</td>\n",
       "      <td>0.005938</td>\n",
       "      <td>0.100756</td>\n",
       "      <td>4.794668e-01</td>\n",
       "      <td>1.128225e-04</td>\n",
       "      <td>3.902865e-01</td>\n",
       "      <td>2.294270e-03</td>\n",
       "      <td>3.994864e-06</td>\n",
       "      <td>2.203607e-06</td>\n",
       "      <td>7.347716e-07</td>\n",
       "      <td>4.205005e-07</td>\n",
       "      <td>9.210566e-08</td>\n",
       "      <td>3.008443e-05</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>7.120603e-07</td>\n",
       "      <td>0.005244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>9.638647e-04</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>1.705775e-05</td>\n",
       "      <td>2.177705e-07</td>\n",
       "      <td>6.212062e-09</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>3.137485e-05</td>\n",
       "      <td>8.554223e-04</td>\n",
       "      <td>3.529570e-05</td>\n",
       "      <td>1.155294e-07</td>\n",
       "      <td>3.284435e-06</td>\n",
       "      <td>2.174506e-06</td>\n",
       "      <td>3.665759e-08</td>\n",
       "      <td>4.478506e-04</td>\n",
       "      <td>4.650679e-04</td>\n",
       "      <td>1.211206e-05</td>\n",
       "      <td>2.320302e-06</td>\n",
       "      <td>1.255611e-07</td>\n",
       "      <td>2.459125e-07</td>\n",
       "      <td>8.899527e-10</td>\n",
       "      <td>6.392489e-03</td>\n",
       "      <td>1.507664e-05</td>\n",
       "      <td>3.401015e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3126</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>1.225638e-04</td>\n",
       "      <td>1.330648e-03</td>\n",
       "      <td>5.290742e-05</td>\n",
       "      <td>6.115026e-04</td>\n",
       "      <td>2.825133e-06</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>7.107466e-06</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>1.578770e-06</td>\n",
       "      <td>1.445539e-08</td>\n",
       "      <td>2.135061e-06</td>\n",
       "      <td>1.027968e-06</td>\n",
       "      <td>2.940293e-04</td>\n",
       "      <td>2.704988e-05</td>\n",
       "      <td>1.144425e-05</td>\n",
       "      <td>2.083481e-05</td>\n",
       "      <td>4.048173e-06</td>\n",
       "      <td>2.643172e-05</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>2.340468e-03</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>4.793614e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.656085e-08</td>\n",
       "      <td>4.648645e-04</td>\n",
       "      <td>3.747970e-04</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.712846e-06</td>\n",
       "      <td>4.472250e-06</td>\n",
       "      <td>8.808629e-06</td>\n",
       "      <td>1.643756e-05</td>\n",
       "      <td>1.192999e-04</td>\n",
       "      <td>2.324675e-03</td>\n",
       "      <td>6.748711e-04</td>\n",
       "      <td>7.841913e-06</td>\n",
       "      <td>1.797475e-08</td>\n",
       "      <td>9.208373e-05</td>\n",
       "      <td>1.928369e-04</td>\n",
       "      <td>1.234607e-04</td>\n",
       "      <td>4.037772e-06</td>\n",
       "      <td>1.639472e-04</td>\n",
       "      <td>8.937501e-06</td>\n",
       "      <td>2.063025e-05</td>\n",
       "      <td>1.227229e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3127</td>\n",
       "      <td>0.001868</td>\n",
       "      <td>0.032602</td>\n",
       "      <td>1.620008e-05</td>\n",
       "      <td>1.283705e-05</td>\n",
       "      <td>3.405659e-05</td>\n",
       "      <td>6.504179e-04</td>\n",
       "      <td>1.054489e-01</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>1.890009e-05</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>4.135342e-04</td>\n",
       "      <td>3.376489e-05</td>\n",
       "      <td>2.495863e-03</td>\n",
       "      <td>1.967650e-02</td>\n",
       "      <td>8.969253e-04</td>\n",
       "      <td>1.574834e-04</td>\n",
       "      <td>1.690211e-04</td>\n",
       "      <td>4.927005e-05</td>\n",
       "      <td>2.873521e-04</td>\n",
       "      <td>2.336423e-04</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>5.826922e-07</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>4.887589e-02</td>\n",
       "      <td>0.006375</td>\n",
       "      <td>3.705476e-04</td>\n",
       "      <td>2.303389e-04</td>\n",
       "      <td>1.743668e-04</td>\n",
       "      <td>0.063292</td>\n",
       "      <td>0.195926</td>\n",
       "      <td>7.786207e-03</td>\n",
       "      <td>4.333588e-01</td>\n",
       "      <td>2.320479e-04</td>\n",
       "      <td>2.547552e-03</td>\n",
       "      <td>2.427308e-03</td>\n",
       "      <td>4.264420e-03</td>\n",
       "      <td>3.207233e-06</td>\n",
       "      <td>4.141561e-05</td>\n",
       "      <td>2.466323e-05</td>\n",
       "      <td>1.434178e-06</td>\n",
       "      <td>8.685702e-04</td>\n",
       "      <td>1.100743e-06</td>\n",
       "      <td>3.044588e-03</td>\n",
       "      <td>6.567472e-08</td>\n",
       "      <td>8.927088e-04</td>\n",
       "      <td>1.204468e-02</td>\n",
       "      <td>2.228847e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3128</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>3.345231e-05</td>\n",
       "      <td>1.176274e-04</td>\n",
       "      <td>1.757207e-05</td>\n",
       "      <td>1.440693e-04</td>\n",
       "      <td>5.411918e-06</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>1.369785e-03</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>1.052319e-04</td>\n",
       "      <td>2.757647e-06</td>\n",
       "      <td>2.441343e-06</td>\n",
       "      <td>1.215714e-05</td>\n",
       "      <td>7.255679e-04</td>\n",
       "      <td>1.776193e-06</td>\n",
       "      <td>4.248767e-06</td>\n",
       "      <td>1.051885e-05</td>\n",
       "      <td>8.755162e-06</td>\n",
       "      <td>5.609869e-06</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>1.119547e-04</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>2.999797e-06</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>1.534645e-06</td>\n",
       "      <td>1.452966e-05</td>\n",
       "      <td>1.911514e-05</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>2.528368e-05</td>\n",
       "      <td>4.395631e-05</td>\n",
       "      <td>1.043876e-05</td>\n",
       "      <td>6.607959e-05</td>\n",
       "      <td>3.738505e-03</td>\n",
       "      <td>8.310549e-03</td>\n",
       "      <td>6.330538e-04</td>\n",
       "      <td>1.585062e-04</td>\n",
       "      <td>5.253386e-06</td>\n",
       "      <td>2.855355e-05</td>\n",
       "      <td>1.086101e-04</td>\n",
       "      <td>3.191976e-05</td>\n",
       "      <td>3.284602e-06</td>\n",
       "      <td>5.761672e-05</td>\n",
       "      <td>2.509627e-05</td>\n",
       "      <td>5.781790e-06</td>\n",
       "      <td>7.223898e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3129</td>\n",
       "      <td>0.004222</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>2.595292e-06</td>\n",
       "      <td>2.950884e-04</td>\n",
       "      <td>2.631509e-04</td>\n",
       "      <td>2.281394e-05</td>\n",
       "      <td>7.910090e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>2.282780e-05</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>6.662969e-06</td>\n",
       "      <td>1.271762e-06</td>\n",
       "      <td>3.870370e-07</td>\n",
       "      <td>1.917479e-05</td>\n",
       "      <td>4.299077e-04</td>\n",
       "      <td>9.659639e-06</td>\n",
       "      <td>2.665155e-06</td>\n",
       "      <td>5.571738e-05</td>\n",
       "      <td>2.121639e-06</td>\n",
       "      <td>4.022555e-06</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>3.395142e-04</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>4.269365e-07</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>5.161713e-06</td>\n",
       "      <td>6.367538e-07</td>\n",
       "      <td>5.421267e-06</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>8.105874e-08</td>\n",
       "      <td>1.194872e-06</td>\n",
       "      <td>3.231482e-06</td>\n",
       "      <td>9.941075e-07</td>\n",
       "      <td>3.176446e-04</td>\n",
       "      <td>9.502537e-04</td>\n",
       "      <td>5.820632e-04</td>\n",
       "      <td>5.014890e-06</td>\n",
       "      <td>8.111192e-07</td>\n",
       "      <td>1.425431e-05</td>\n",
       "      <td>2.082707e-06</td>\n",
       "      <td>2.616074e-06</td>\n",
       "      <td>4.458506e-07</td>\n",
       "      <td>2.302143e-03</td>\n",
       "      <td>8.492467e-05</td>\n",
       "      <td>2.439178e-06</td>\n",
       "      <td>3.807932e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>3902</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>2.692790e-07</td>\n",
       "      <td>1.392818e-04</td>\n",
       "      <td>3.632546e-04</td>\n",
       "      <td>3.666391e-05</td>\n",
       "      <td>2.516073e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>5.034942e-05</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>5.608847e-07</td>\n",
       "      <td>8.443988e-08</td>\n",
       "      <td>4.424959e-08</td>\n",
       "      <td>3.241649e-06</td>\n",
       "      <td>5.664256e-04</td>\n",
       "      <td>1.966830e-05</td>\n",
       "      <td>4.358430e-06</td>\n",
       "      <td>1.377685e-04</td>\n",
       "      <td>1.753900e-06</td>\n",
       "      <td>9.672356e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.599161e-04</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.128838e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.651635e-07</td>\n",
       "      <td>1.488061e-06</td>\n",
       "      <td>1.090116e-05</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>8.845261e-08</td>\n",
       "      <td>5.673692e-07</td>\n",
       "      <td>2.185301e-06</td>\n",
       "      <td>7.444148e-07</td>\n",
       "      <td>2.017738e-04</td>\n",
       "      <td>3.374573e-04</td>\n",
       "      <td>1.702022e-03</td>\n",
       "      <td>2.183509e-07</td>\n",
       "      <td>3.351120e-08</td>\n",
       "      <td>2.855817e-06</td>\n",
       "      <td>4.701814e-07</td>\n",
       "      <td>2.122393e-07</td>\n",
       "      <td>2.414436e-07</td>\n",
       "      <td>1.602291e-02</td>\n",
       "      <td>2.339808e-05</td>\n",
       "      <td>2.259146e-06</td>\n",
       "      <td>5.595793e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>3903</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2.418103e-06</td>\n",
       "      <td>2.474411e-04</td>\n",
       "      <td>7.793277e-05</td>\n",
       "      <td>3.450090e-05</td>\n",
       "      <td>3.203852e-08</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.091073e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.682169e-07</td>\n",
       "      <td>1.466343e-08</td>\n",
       "      <td>1.076064e-07</td>\n",
       "      <td>2.007611e-07</td>\n",
       "      <td>1.504268e-04</td>\n",
       "      <td>3.400251e-05</td>\n",
       "      <td>3.794539e-06</td>\n",
       "      <td>1.547392e-04</td>\n",
       "      <td>1.618792e-06</td>\n",
       "      <td>2.004600e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.284377e-03</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>7.070109e-08</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.374649e-08</td>\n",
       "      <td>1.038312e-05</td>\n",
       "      <td>3.036143e-05</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>3.591797e-08</td>\n",
       "      <td>4.240455e-07</td>\n",
       "      <td>1.551022e-06</td>\n",
       "      <td>1.363590e-07</td>\n",
       "      <td>1.432590e-05</td>\n",
       "      <td>1.126615e-04</td>\n",
       "      <td>8.413609e-05</td>\n",
       "      <td>4.325434e-07</td>\n",
       "      <td>7.853837e-09</td>\n",
       "      <td>1.182301e-05</td>\n",
       "      <td>1.135056e-06</td>\n",
       "      <td>1.329223e-06</td>\n",
       "      <td>6.008780e-07</td>\n",
       "      <td>3.952625e-03</td>\n",
       "      <td>5.511012e-06</td>\n",
       "      <td>6.515145e-07</td>\n",
       "      <td>3.573783e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>3904</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.099465e-05</td>\n",
       "      <td>9.337877e-05</td>\n",
       "      <td>1.634578e-05</td>\n",
       "      <td>8.988440e-05</td>\n",
       "      <td>1.229814e-06</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>2.575660e-05</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>7.194992e-06</td>\n",
       "      <td>3.232979e-07</td>\n",
       "      <td>5.068840e-07</td>\n",
       "      <td>7.551430e-06</td>\n",
       "      <td>1.616150e-04</td>\n",
       "      <td>8.896222e-07</td>\n",
       "      <td>4.917642e-07</td>\n",
       "      <td>3.038611e-06</td>\n",
       "      <td>8.085279e-07</td>\n",
       "      <td>4.941950e-06</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>1.765404e-04</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>4.938819e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>5.427270e-07</td>\n",
       "      <td>2.785574e-06</td>\n",
       "      <td>5.802608e-06</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>8.832764e-07</td>\n",
       "      <td>4.378901e-06</td>\n",
       "      <td>1.285613e-06</td>\n",
       "      <td>8.524936e-06</td>\n",
       "      <td>4.783742e-04</td>\n",
       "      <td>2.380906e-03</td>\n",
       "      <td>1.889450e-04</td>\n",
       "      <td>1.027952e-05</td>\n",
       "      <td>3.110814e-07</td>\n",
       "      <td>1.133624e-05</td>\n",
       "      <td>1.826907e-05</td>\n",
       "      <td>1.181306e-05</td>\n",
       "      <td>3.889178e-07</td>\n",
       "      <td>7.185910e-05</td>\n",
       "      <td>1.804710e-05</td>\n",
       "      <td>1.360694e-06</td>\n",
       "      <td>7.549015e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>3905</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>9.349877e-07</td>\n",
       "      <td>2.897043e-09</td>\n",
       "      <td>1.360930e-08</td>\n",
       "      <td>2.737833e-08</td>\n",
       "      <td>1.765427e-02</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.666289e-08</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.614539e-05</td>\n",
       "      <td>3.251577e-09</td>\n",
       "      <td>2.272466e-04</td>\n",
       "      <td>7.495165e-08</td>\n",
       "      <td>4.059368e-07</td>\n",
       "      <td>1.741021e-05</td>\n",
       "      <td>4.617530e-07</td>\n",
       "      <td>1.403474e-09</td>\n",
       "      <td>3.055238e-08</td>\n",
       "      <td>4.119734e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.097873e-09</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>9.801980e-01</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.178972e-07</td>\n",
       "      <td>1.237006e-05</td>\n",
       "      <td>4.006409e-08</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>2.805889e-05</td>\n",
       "      <td>3.204079e-04</td>\n",
       "      <td>2.950669e-07</td>\n",
       "      <td>4.707098e-04</td>\n",
       "      <td>5.880752e-07</td>\n",
       "      <td>8.497389e-07</td>\n",
       "      <td>5.535009e-10</td>\n",
       "      <td>4.641344e-07</td>\n",
       "      <td>5.805668e-09</td>\n",
       "      <td>7.169170e-09</td>\n",
       "      <td>2.958758e-05</td>\n",
       "      <td>7.718703e-08</td>\n",
       "      <td>1.964780e-06</td>\n",
       "      <td>6.251173e-12</td>\n",
       "      <td>1.060830e-07</td>\n",
       "      <td>1.251617e-05</td>\n",
       "      <td>4.916669e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>3906</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.097097e-06</td>\n",
       "      <td>1.333163e-04</td>\n",
       "      <td>3.200663e-05</td>\n",
       "      <td>2.775637e-05</td>\n",
       "      <td>9.644702e-08</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.585497e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>3.416702e-07</td>\n",
       "      <td>6.410163e-08</td>\n",
       "      <td>1.649266e-07</td>\n",
       "      <td>4.274219e-06</td>\n",
       "      <td>4.257003e-05</td>\n",
       "      <td>8.205339e-06</td>\n",
       "      <td>7.160952e-07</td>\n",
       "      <td>1.318424e-05</td>\n",
       "      <td>4.357608e-07</td>\n",
       "      <td>7.028999e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>7.395596e-04</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>9.079032e-08</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>2.189728e-08</td>\n",
       "      <td>4.557222e-06</td>\n",
       "      <td>2.222234e-05</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>8.976022e-08</td>\n",
       "      <td>8.475187e-07</td>\n",
       "      <td>1.047357e-06</td>\n",
       "      <td>1.614747e-07</td>\n",
       "      <td>2.474583e-05</td>\n",
       "      <td>1.472671e-04</td>\n",
       "      <td>8.589283e-05</td>\n",
       "      <td>1.351910e-07</td>\n",
       "      <td>1.652482e-08</td>\n",
       "      <td>2.854900e-06</td>\n",
       "      <td>9.722719e-07</td>\n",
       "      <td>3.358905e-07</td>\n",
       "      <td>1.054960e-07</td>\n",
       "      <td>2.254390e-03</td>\n",
       "      <td>9.878531e-05</td>\n",
       "      <td>9.046755e-07</td>\n",
       "      <td>1.539940e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>782 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id         0         1             2             3             4  \\\n",
       "0    3125  0.000011  0.000002  2.116810e-07  4.708937e-08  1.865657e-04   \n",
       "1    3126  0.000413  0.000020  1.225638e-04  1.330648e-03  5.290742e-05   \n",
       "2    3127  0.001868  0.032602  1.620008e-05  1.283705e-05  3.405659e-05   \n",
       "3    3128  0.000691  0.000010  3.345231e-05  1.176274e-04  1.757207e-05   \n",
       "4    3129  0.004222  0.000031  2.595292e-06  2.950884e-04  2.631509e-04   \n",
       "..    ...       ...       ...           ...           ...           ...   \n",
       "777  3902  0.007722  0.000045  2.692790e-07  1.392818e-04  3.632546e-04   \n",
       "778  3903  0.000128  0.000006  2.418103e-06  2.474411e-04  7.793277e-05   \n",
       "779  3904  0.000417  0.000003  1.099465e-05  9.337877e-05  1.634578e-05   \n",
       "780  3905  0.000004  0.000872  9.349877e-07  2.897043e-09  1.360930e-08   \n",
       "781  3906  0.000093  0.000004  1.097097e-06  1.333163e-04  3.200663e-05   \n",
       "\n",
       "                5             6         7             8         9        10  \\\n",
       "0    1.124369e-07  3.247155e-04  0.000002  1.424222e-07  0.005938  0.100756   \n",
       "1    6.115026e-04  2.825133e-06  0.000066  7.107466e-06  0.000011  0.000024   \n",
       "2    6.504179e-04  1.054489e-01  0.000152  1.890009e-05  0.000041  0.002011   \n",
       "3    1.440693e-04  5.411918e-06  0.000118  1.369785e-03  0.000056  0.000156   \n",
       "4    2.281394e-05  7.910090e-07  0.000003  2.282780e-05  0.000076  0.000025   \n",
       "..            ...           ...       ...           ...       ...       ...   \n",
       "777  3.666391e-05  2.516073e-07  0.000004  5.034942e-05  0.000009  0.000006   \n",
       "778  3.450090e-05  3.203852e-08  0.000003  1.091073e-06  0.000002  0.000001   \n",
       "779  8.988440e-05  1.229814e-06  0.000017  2.575660e-05  0.000022  0.000035   \n",
       "780  2.737833e-08  1.765427e-02  0.000002  1.666289e-08  0.000002  0.000002   \n",
       "781  2.775637e-05  9.644702e-08  0.000002  2.585497e-07  0.000002  0.000010   \n",
       "\n",
       "               11            12            13            14            15  \\\n",
       "0    4.794668e-01  1.128225e-04  3.902865e-01  2.294270e-03  3.994864e-06   \n",
       "1    1.578770e-06  1.445539e-08  2.135061e-06  1.027968e-06  2.940293e-04   \n",
       "2    4.135342e-04  3.376489e-05  2.495863e-03  1.967650e-02  8.969253e-04   \n",
       "3    1.052319e-04  2.757647e-06  2.441343e-06  1.215714e-05  7.255679e-04   \n",
       "4    6.662969e-06  1.271762e-06  3.870370e-07  1.917479e-05  4.299077e-04   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "777  5.608847e-07  8.443988e-08  4.424959e-08  3.241649e-06  5.664256e-04   \n",
       "778  2.682169e-07  1.466343e-08  1.076064e-07  2.007611e-07  1.504268e-04   \n",
       "779  7.194992e-06  3.232979e-07  5.068840e-07  7.551430e-06  1.616150e-04   \n",
       "780  1.614539e-05  3.251577e-09  2.272466e-04  7.495165e-08  4.059368e-07   \n",
       "781  3.416702e-07  6.410163e-08  1.649266e-07  4.274219e-06  4.257003e-05   \n",
       "\n",
       "               16            17            18            19            20  \\\n",
       "0    2.203607e-06  7.347716e-07  4.205005e-07  9.210566e-08  3.008443e-05   \n",
       "1    2.704988e-05  1.144425e-05  2.083481e-05  4.048173e-06  2.643172e-05   \n",
       "2    1.574834e-04  1.690211e-04  4.927005e-05  2.873521e-04  2.336423e-04   \n",
       "3    1.776193e-06  4.248767e-06  1.051885e-05  8.755162e-06  5.609869e-06   \n",
       "4    9.659639e-06  2.665155e-06  5.571738e-05  2.121639e-06  4.022555e-06   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "777  1.966830e-05  4.358430e-06  1.377685e-04  1.753900e-06  9.672356e-07   \n",
       "778  3.400251e-05  3.794539e-06  1.547392e-04  1.618792e-06  2.004600e-06   \n",
       "779  8.896222e-07  4.917642e-07  3.038611e-06  8.085279e-07  4.941950e-06   \n",
       "780  1.741021e-05  4.617530e-07  1.403474e-09  3.055238e-08  4.119734e-07   \n",
       "781  8.205339e-06  7.160952e-07  1.318424e-05  4.357608e-07  7.028999e-07   \n",
       "\n",
       "           21            22        23  ...        36            37        38  \\\n",
       "0    0.000004  7.120603e-07  0.005244  ...  0.001091  9.638647e-04  0.000089   \n",
       "1    0.000180  2.340468e-03  0.000217  ...  0.000310  4.793614e-06  0.000002   \n",
       "2    0.000258  5.826922e-07  0.000569  ...  0.000390  4.887589e-02  0.006375   \n",
       "3    0.000086  1.119547e-04  0.000133  ...  0.000285  2.999797e-06  0.000039   \n",
       "4    0.000007  3.395142e-04  0.000008  ...  0.000016  4.269365e-07  0.000011   \n",
       "..        ...           ...       ...  ...       ...           ...       ...   \n",
       "777  0.000002  2.599161e-04  0.000001  ...  0.000004  1.128838e-07  0.000002   \n",
       "778  0.000002  1.284377e-03  0.000007  ...  0.000003  7.070109e-08  0.000002   \n",
       "779  0.000040  1.765404e-04  0.000032  ...  0.000110  4.938819e-07  0.000003   \n",
       "780  0.000003  1.097873e-09  0.000007  ...  0.000006  9.801980e-01  0.000001   \n",
       "781  0.000001  7.395596e-04  0.000014  ...  0.000004  9.079032e-08  0.000003   \n",
       "\n",
       "               39            40            41        42        43  \\\n",
       "0    1.705775e-05  2.177705e-07  6.212062e-09  0.000386  0.000093   \n",
       "1    3.656085e-08  4.648645e-04  3.747970e-04  0.000015  0.000007   \n",
       "2    3.705476e-04  2.303389e-04  1.743668e-04  0.063292  0.195926   \n",
       "3    1.534645e-06  1.452966e-05  1.911514e-05  0.000014  0.000024   \n",
       "4    5.161713e-06  6.367538e-07  5.421267e-06  0.000096  0.000048   \n",
       "..            ...           ...           ...       ...       ...   \n",
       "777  2.651635e-07  1.488061e-06  1.090116e-05  0.000015  0.000004   \n",
       "778  2.374649e-08  1.038312e-05  3.036143e-05  0.000024  0.000007   \n",
       "779  5.427270e-07  2.785574e-06  5.802608e-06  0.000009  0.000012   \n",
       "780  3.178972e-07  1.237006e-05  4.006409e-08  0.000007  0.000009   \n",
       "781  2.189728e-08  4.557222e-06  2.222234e-05  0.000060  0.000014   \n",
       "\n",
       "               44            45            46            47            48  \\\n",
       "0    3.137485e-05  8.554223e-04  3.529570e-05  1.155294e-07  3.284435e-06   \n",
       "1    1.712846e-06  4.472250e-06  8.808629e-06  1.643756e-05  1.192999e-04   \n",
       "2    7.786207e-03  4.333588e-01  2.320479e-04  2.547552e-03  2.427308e-03   \n",
       "3    2.528368e-05  4.395631e-05  1.043876e-05  6.607959e-05  3.738505e-03   \n",
       "4    8.105874e-08  1.194872e-06  3.231482e-06  9.941075e-07  3.176446e-04   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "777  8.845261e-08  5.673692e-07  2.185301e-06  7.444148e-07  2.017738e-04   \n",
       "778  3.591797e-08  4.240455e-07  1.551022e-06  1.363590e-07  1.432590e-05   \n",
       "779  8.832764e-07  4.378901e-06  1.285613e-06  8.524936e-06  4.783742e-04   \n",
       "780  2.805889e-05  3.204079e-04  2.950669e-07  4.707098e-04  5.880752e-07   \n",
       "781  8.976022e-08  8.475187e-07  1.047357e-06  1.614747e-07  2.474583e-05   \n",
       "\n",
       "               49            50            51            52            53  \\\n",
       "0    2.174506e-06  3.665759e-08  4.478506e-04  4.650679e-04  1.211206e-05   \n",
       "1    2.324675e-03  6.748711e-04  7.841913e-06  1.797475e-08  9.208373e-05   \n",
       "2    4.264420e-03  3.207233e-06  4.141561e-05  2.466323e-05  1.434178e-06   \n",
       "3    8.310549e-03  6.330538e-04  1.585062e-04  5.253386e-06  2.855355e-05   \n",
       "4    9.502537e-04  5.820632e-04  5.014890e-06  8.111192e-07  1.425431e-05   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "777  3.374573e-04  1.702022e-03  2.183509e-07  3.351120e-08  2.855817e-06   \n",
       "778  1.126615e-04  8.413609e-05  4.325434e-07  7.853837e-09  1.182301e-05   \n",
       "779  2.380906e-03  1.889450e-04  1.027952e-05  3.110814e-07  1.133624e-05   \n",
       "780  8.497389e-07  5.535009e-10  4.641344e-07  5.805668e-09  7.169170e-09   \n",
       "781  1.472671e-04  8.589283e-05  1.351910e-07  1.652482e-08  2.854900e-06   \n",
       "\n",
       "               54            55            56            57            58  \\\n",
       "0    2.320302e-06  1.255611e-07  2.459125e-07  8.899527e-10  6.392489e-03   \n",
       "1    1.928369e-04  1.234607e-04  4.037772e-06  1.639472e-04  8.937501e-06   \n",
       "2    8.685702e-04  1.100743e-06  3.044588e-03  6.567472e-08  8.927088e-04   \n",
       "3    1.086101e-04  3.191976e-05  3.284602e-06  5.761672e-05  2.509627e-05   \n",
       "4    2.082707e-06  2.616074e-06  4.458506e-07  2.302143e-03  8.492467e-05   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "777  4.701814e-07  2.122393e-07  2.414436e-07  1.602291e-02  2.339808e-05   \n",
       "778  1.135056e-06  1.329223e-06  6.008780e-07  3.952625e-03  5.511012e-06   \n",
       "779  1.826907e-05  1.181306e-05  3.889178e-07  7.185910e-05  1.804710e-05   \n",
       "780  2.958758e-05  7.718703e-08  1.964780e-06  6.251173e-12  1.060830e-07   \n",
       "781  9.722719e-07  3.358905e-07  1.054960e-07  2.254390e-03  9.878531e-05   \n",
       "\n",
       "               59            60  \n",
       "0    1.507664e-05  3.401015e-06  \n",
       "1    2.063025e-05  1.227229e-05  \n",
       "2    1.204468e-02  2.228847e-03  \n",
       "3    5.781790e-06  7.223898e-03  \n",
       "4    2.439178e-06  3.807932e-03  \n",
       "..            ...           ...  \n",
       "777  2.259146e-06  5.595793e-03  \n",
       "778  6.515145e-07  3.573783e-05  \n",
       "779  1.360694e-06  7.549015e-04  \n",
       "780  1.251617e-05  4.916669e-09  \n",
       "781  9.046755e-07  1.539940e-04  \n",
       "\n",
       "[782 rows x 62 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission=pd.read_csv('./data/sample_submission.csv')\n",
    "submission.iloc[:,1:]=pred\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('final_submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
